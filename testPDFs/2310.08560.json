[{"file_id": "2310.08560", "article": "Chunk # 0.\nPreprint\nMEMGPT: T OWARDS LLM S AS OPERATING SYSTEMS\nCharles Packer Vivian Fang Shishir G Patil\nKevin Lin Sarah Wooders Joseph E Gonzalez\nUC Berkeley\nhttps://memgpt.ai\nABSTRACT\nLarge language models (LLMs) have revolutionized AI, but are constrained by\nlimited context windows, hindering their utility in tasks like extended conversa-\ntions and document analysis To enable using context beyond limited context win-\ndows, we propose virtual context management, a technique drawing inspiration\nfrom hierarchical memory systems in traditional operating systems that provide\nthe appearance of large memory resources through data movement between fast\nand slow memory Using this technique, we introduce MemGPT (Memory-GPT),\na system that intelligently manages different memory tiers in order to effectively\nprovide extended context within the LLM\u2019s limited context window, and utilizes\ninterrupts to manage control flow between itself and the user We evaluate our\nOS-inspired design in two domains where the limited context windows of modern\nLLMs severely handicaps their performance: document analysis, where MemGPT\nis able to analyze large documents that far exceed the underlying LLM\u2019s con-\ntext window, and multi-session chat, where MemGPT can create conversational\nagents that remember, reflect, and evolve dynamically through long-term interac-\ntions with their users We release MemGPT code and data for our experiments at\nhttps://memgpt.ai 1 I NTRODUCTION\nIn recent years, large language models (LLMs) and their underlying transformer architec-\nture (Vaswani et al., 2017; Devlin et al., 2018; Brown et al., 2020; Ouyang et al., 2022) have become\nthe cornerstone of conversational AI and have led to a wide array of consumer and enterprise applica-\ntions Despite these advances, the limited fixed-length context windows used by LLMs significantly\nhinders their applicability to long conversations or reasoning about long documents For example,\nthe most widely used open-source LLMs can only support a few dozen back-and-forth messages or\nreason about a short document before exceeding their maximum input length (Touvron et al., 2023) Naively extending the context length of transformers incurs a quadratic increase in computational\ntime and memory cost due to the transformer architecture\u2019s self-attention mechanism, making the\ndesign of new long-context architectures a pressing research challenge (Dai et al., 2019; Kitaev\net al., 2020; Beltagy et al., 2020) While developing longer models is an active area of research\n(Dong et al., 2023), even if we could overcome the computational challenges of context scaling,\nrecent research shows that long-context models struggle to utilize additional context effectively (Liu\net al., 2023a) As consequence, given the considerable resources needed to train state-of-the-art\nLLMs and apparent diminishing returns of context scaling, there is a critical need for alternative\ntechniques to support long context In this paper, we study how to provide the illusion of an infinite context while continuing to use\nfixed-context models Our approach borrows from the idea of virtual memory paging that was\ndeveloped to enable applications to work on datasets that far exceed the available memory We\nleverage the recent progress in function calling abilities of LLM agents (Schick et al., 2023; Liu et al.,\n2023b) to design MemGPT, an OS-inspired LLM system for virtual context management  We\ndraw inspiration from traditional OSes\u2019 hierarchical memory management to effectively \u201cpage\u201d in\n1arXiv:2310.08560v1  [cs.AI]  12 Oct 2023Preprint\nLLM processorParserVirtual contextExternal context\u221e tokensMain contextMax token limitYieldEventMessage\ud83e\uddd1Document upload\ud83d\udcc4System message\ud83d\udd14FunctionRead memorySend message\ud83d\udce3\u2026ParserTimer\u23f1\u2026Pause interrupts\ud83d\udd15Write memory\nFigure 1: In MemGPT (components shaded), a fixed-context LLM is augmented with a hierarchical\nmemory system and functions that let it manage its own memory The LLM processor takes main\ncontext (analogous to OS main memory/RAM) as input, and outputs text interpreted by a parser,\nresulting either in a yield or a function call MemGPT uses functions to move data between main\ncontext and external context (analogous to OS disk memory) When the processor generates a\nfunction call, it can request control ahead of time to chain together functions When yielding, the\nprocessor is paused until the next external event (e.g., a user message or scheduled interrupt) and out information between context windows (analogous to \u201cmain memory\u201d in operating systems)\nand external storage MemGPT manages the control flow between the memory management, the\nLLM processing module, and user This design allows for repeated context modifications during a\nsingle task, allowing the agent to more effectively utilize its limited context In MemGPT, we treat context windows as a constrained memory resource, and design a memory\nhiearchy for LLMs analogous to memory tiers used in traditional OSes (Patterson et al., 1988) Applications in traditional OSes interact with virtual memory , which provides an illusion of there\nbeing more memory resources than are actually available in physical (i.e., main) memory by the OS\npaging overflow data to disk and retrieving data (via a page fault) back into memory when accessed\nby applications", "summary": "Iteration 4:\nLarge language models (LLMs), including those with long-context architectures, have revolutionized AI by enabling conversational AI and a wide range of applications. However, the limited fixed-length context windows of LLMs pose challenges for long conversations and analyzing lengthy documents. To overcome this, we propose virtual context management, inspired by hierarchical memory systems in traditional operating systems. We introduce MemGPT (Memory-GPT), an OS-inspired LLM system that intelligently manages memory tiers to provide extended context within the limited context window. MemGPT utilizes interrupts to manage control flow between the system and the user. In document analysis, MemGPT can handle large documents that exceed the LLM's context window. In multi-session chat, MemGPT creates conversational agents that remember, reflect, and evolve dynamically through long-term interactions. Our approach treats context windows as a constrained memory resource and implements a memory hierarchy similar to traditional OSes. By leveraging virtual memory paging and the function calling abilities of LLM agents, MemGPT provides the illusion of an infinite context, allowing LLMs to handle more information effectively. LLMs at UC Berkeley are using the MemGPT code and data, which incorporates a transformer architecture with a self-attention mechanism. The memory hierarchy includes main and external context, effectively \"paging\" information between context windows and external storage, similar to traditional OS memory tiers. Virtual memory provides an illusion of expanded resources, enabling LLMs to work with datasets beyond physical memory limitations. For more details, refer to arXiv:2310.08560v1 [cs.AI] 12 Oct 2023.", "clean_entities": ["MemGPT (Memory-GPT)", "LLMs (Large Language Models)", "UC Berkeley", "context windows", "extended context", "limited context window", "hierarchical memory systems", "virtual context management", "MemGPT code and data", "transformer architecture", "self-attention mechanism", "long-context architectures", "long-context models", "alternative techniques", "virtual memory paging", "function calling abilities", "OS-inspired LLM system", "hierarchical memory management", "main context", "external context", "memory hiearchy", "memory tiers", "virtual memory", "physical memory", "page fault", "large language models (LLMs) and their underlying transformer architecture", "limited fixed-length context windows used by LLMs", "long conversations or reasoning about long documents", "computational challenges of context scaling", "illusion of an infinite context", "recent progress in function calling abilities of LLM agents", "OS-inspired LLM system for virtual context management", "hierarchical memory management to effectively \"page\" in and out information between context windows and external storage", "memory hiearchy for LLMs analogous to memory tiers used in traditional OSes", "virtual memory that provides an illusion of there being more memory resources than are actually available in physical memory", "https://memgpt.ai", "arXiv:2310.08560v1 [cs.AI] 12 Oct 2023"], "dirty_entities": ["Entities:", "", "Keywords:", "", "Key Phrases:", "", "References:"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "Large language models (LLMs) and their impact on AI", "justification": "The summary mentions that LLMs have revolutionized AI and enabled conversational AI and a wide range of applications."}, {"topic": "Challenges of limited fixed-length context windows in LLMs", "justification": "The summary highlights the challenges posed by the limited fixed-length context windows of LLMs for long conversations and analyzing lengthy documents."}, {"topic": "Introduction of MemGPT (Memory-GPT) and its purpose", "justification": "The summary introduces MemGPT as an OS-inspired LLM system that intelligently manages memory tiers to provide extended context within the limited context window."}, {"topic": "MemGPT's use of interrupts and control flow management", "justification": "The summary mentions that MemGPT utilizes interrupts to manage control flow between the system and the user."}, {"topic": "MemGPT's ability to handle large documents in document analysis", "justification": "The summary states that MemGPT can handle large documents that exceed the LLM's context window, making it relevant to the topic."}, {"topic": "MemGPT's role in creating conversational agents for multi-session chat", "justification": "The summary mentions that MemGPT creates conversational agents that remember, reflect, and evolve dynamically through long-term interactions, making it a significant topic."}, {"topic": "MemGPT's approach of treating context windows as a constrained memory resource", "justification": "The summary mentions that MemGPT treats context windows as a constrained memory resource and implements a memory hierarchy similar to traditional OSes."}, {"topic": "MemGPT's use of virtual memory paging and function calling abilities of LLM agents", "justification": "The summary mentions that MemGPT leverages virtual memory paging and the function calling abilities of LLM agents to provide the illusion of an infinite context."}, {"topic": "Use of MemGPT by LLMs at UC Berkeley and its architecture", "justification": "The summary mentions that LLMs at UC Berkeley are using the MemGPT code and data, which incorporates a transformer architecture with a self-attention mechanism."}, {"topic": "MemGPT's memory hierarchy and virtual memory's role in expanding resources", "justification": "The summary mentions that MemGPT implements a memory hierarchy including main and external context and leverages virtual memory to provide an illusion of expanded resources."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does MemGPT address the challenges posed by the limited fixed-length context windows of LLMs?"}, {"question_type": "Analytical Question", "question": "What are some key features of MemGPT that enable it to handle large documents and long conversations?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a scenario where MemGPT is used in a multi-session chat. How could the ability to remember, reflect, and evolve dynamically through long-term interactions enhance the user experience?"}, {"question_type": "Contextual/Relational Question", "question": "How does MemGPT's memory hierarchy, inspired by traditional operating systems, contribute to its ability to handle more information effectively?"}, {"question_type": "User-Interactive Question", "question": "If you were to design a conversational agent using MemGPT, how would you leverage its virtual memory capabilities to enhance the agent's performance and user interaction?"}], "knowledge_triplets": [{"subject": "MemGPT (Memory-GPT)", "relationship": "remembers", "target": "reflects, and evolves dynamically"}, {"subject": "LLMs", "relationship": "have revolutionized", "target": "AI"}, {"subject": "LLMs", "relationship": "are constrained by", "target": "limited context windows"}, {"subject": "LLMs", "relationship": "hindering", "target": "utility in tasks like extended conversations and document analysis"}, {"subject": "context", "relationship": "beyond limited context windows", "target": "enable using"}, {"subject": "technique", "relationship": "drawing inspiration from", "target": "hierarchical memory systems"}, {"subject": "memory movement", "relationship": "between fast and slow memory", "target": "provide the appearance of large memory resources"}, {"subject": "MemGPT", "relationship": "intelligently manages", "target": "different memory tiers"}, {"subject": "MemGPT", "relationship": "effectively provide", "target": "extended context within the LLM's limited context window"}, {"subject": "MemGPT", "relationship": "utilizes", "target": "interrupts to manage control flow"}, {"subject": "MemGPT", "relationship": "evaluates", "target": "OS-inspired design in two domains"}, {"subject": "limited context windows", "relationship": "severely handicaps", "target": "performance of modern LLMs"}, {"subject": "MemGPT", "relationship": "is able to analyze", "target": "large documents that far exceed the underlying LLM's context window"}, {"subject": "MemGPT", "relationship": "can create", "target": "conversational agents that remember, reflect, and evolve dynamically"}, {"subject": "MemGPT code and data", "relationship": "released at", "target": "https://memgpt.ai"}, {"subject": "LLMs", "relationship": "have become", "target": "the cornerstone of conversational AI"}, {"subject": "transformer architecture", "relationship": "have become", "target": "the cornerstone of conversational AI"}, {"subject": "LLMs", "relationship": "have led to", "target": "a wide array of consumer and enterprise applications"}, {"subject": "LLMs", "relationship": "significantly hinders", "target": "their applicability to long conversations or reasoning about long documents"}, {"subject": "LLMs", "relationship": "can only support", "target": "a few dozen back-and-forth messages"}, {"subject": "LLMs", "relationship": "can only support", "target": "reasoning about a short document"}, {"subject": "extending the context length of transformers", "relationship": "incurs", "target": "a quadratic increase in computational time and memory cost"}, {"subject": "long-context models", "relationship": "struggle to utilize", "target": "additional context effectively"}, {"subject": "alternative techniques", "relationship": "needed to support", "target": "long context"}, {"subject": "virtual memory paging", "relationship": "developed to enable", "target": "applications to work on datasets that far exceed the available memory"}, {"subject": "function calling abilities of LLM agents", "relationship": "leverage", "target": "to design MemGPT"}, {"subject": "MemGPT", "relationship": "an OS-inspired LLM system", "target": "for virtual context management"}, {"subject": "traditional OSes' hierarchical memory management", "relationship": "inspiration for", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "augmented with", "target": "a hierarchical memory system"}, {"subject": "LLM processor", "relationship": "takes main context", "target": "as input"}, {"subject": "LLM processor", "relationship": "outputs", "target": "text interpreted by a parser"}, {"subject": "MemGPT", "relationship": "uses functions", "target": "to move data between main context and external context"}, {"subject": "processor", "relationship": "generates", "target": "a function call"}, {"subject": "processor", "relationship": "can request control ahead of time", "target": "to chain together functions"}, {"subject": "processor", "relationship": "paused until", "target": "the next external event"}, {"subject": "MemGPT", "relationship": "manages", "target": "control flow between memory management, LLM processing module, and user"}, {"subject": "MemGPT", "relationship": "allows for repeated context modifications", "target": "during a single task"}, {"subject": "MemGPT", "relationship": "treats context windows", "target": "as a constrained memory resource"}, {"subject": "MemGPT", "relationship": "design", "target": "a memory hierarchy for LLMs analogous to memory tiers used in traditional OSes"}, {"subject": "traditional OSes", "relationship": "interact with", "target": "virtual memory"}, {"subject": "virtual memory", "relationship": "provides an illusion of", "target": "more memory resources than are actually available"}, {"subject": "OS", "relationship": "paging overflow data to disk", "target": "and retrieving data back into memory"}, {"subject": "MemGPT (Memory-GPT)", "relationship": "can create conversational agents that remember", "target": "reflect, and evolve dynamically"}], "timestamp": "2024-01-14T17:26:35.042342"}, {"file_id": "2310.08560", "article": "Chunk # 1.\nTo provide a similar illusion of longer context length (analogous to virtual memory),\nwe allow the LLM to manage what is placed in its own context (analogous to physical memory) via\nan \u2018LLM OS\u2019, which we call MemGPT MemGPT enables the LLM to retrieve relevant historical\ndata missing from what is placed in-context, similar to an OS page fault Additionally, the agent can\niteratively modify what is in context for a single task, in the same way a process may access virtual\nmemory repeatedly Figure 1 illustrates the components of MemGPT The combined use of a memory-hierarchy, OS functions and event-based control flow allow\nMemGPT to handle unbounded context using LLMs that have finite context windows To demon-\nstrate the utility of our new OS-inspired LLM system, we evaluate MemGPT on two domains where\nthe performance of existing LLMs is severely limited by finite context: document analysis, where the\nlength of standard text files can quickly exceed the input capacity of modern LLMs, and conversa-\ntional agents, where LLMs bound by limited conversation windows lack context awareness, persona\nconsistency, and long-term memory during extended conversations In both settings, MemGPT is\nable to overcome the limitations of finite context to outperform existing LLM-based approaches 2 M EMORY -GPT (M EMGPT)\nIn this section, we outline the implementation of MemGPT, an OS-inspired LLM system that teaches\nLLMs to manage their own memory to achieve unbounded context MemGPT\u2019s multi-level mem-\nory architecture delineates between two primary memory types: main context (analogous to main\nmemory/physical memory/RAM) and external context (analogous to disk memory/disk storage) Main context is the standard fixed-context window in modern language models\u2014anything in main\ncontext is considered in-context and can be accessed by the LLM processor during inference Ex-\nternal context refers to any information that is held outside of the LLMs fixed context window This\nout-of-context data must always be explicitly moved into main context in order for it to be passed to\n2Preprint\nTable 1: Comparing context lengths of commonly used models / APIs (data collected 9/2023) *Assuming a preprompt of 1k tokens, and an average message size of \u223c50 tokens ( \u223c250 characters) Model / API designation Availability Max Tokens Max conversation length*\nllama-1 model family Open source 2k tokens 20 total messages\nllama-2 model family Open source 4k tokens 60 total messages\ngpt-3.5-turbo API 4k tokens 60 total messages\ngpt-4 API 8k tokens 140 total messages\ngpt-3.5-turbo-16k API 16k tokens 300 total messages\ngpt-4-32k Limited API 32k tokens \u223c600 total messages\nclaude-instant-1 Limited API 100k tokens \u223c2000 total messages\nclaude-2 Limited API 100k tokens \u223c2000 total messages\nthe LLM processor during inference MemGPT provides function calls that the LLM processor can\nuse to manage its own memory without any user intervention 2.1 M AIN CONTEXT\nIn MemGPT we refer to the LLM inputs (that are bound by the maximum number of input tokens)\nas the system\u2019s main context In LLM-based conversational agents, a significant portion of main\ncontext tokens is generally used to hold a \u2018system message\u2019 or \u2018preprompt\u2019 that dictates the nature\nof the interaction to the system, while the remainder of the tokens can be used to hold conversation\ndata (Touvron et al., 2023; SillyTavern, 2023) This preprompt is the main way to enable the system\nto adopt various distinct personas without requiring finetuning of the base model; depending on\nthe use case, the preprompt can range from basic primers (e.g., \u2018You are a helpful assistant.\u2019) to\ncomplex instructions comprising of thousands of tokens (e.g., a fictional character card that includes\nthe character\u2019s background and example dialogue) Beyond conversational agents, large preprompts\nare also common when LLMs are used to solve complex tasks that require long instructions and/or\ninstructions with many in-context examples (Liu et al., 2023b) Because of the importance of the preprompt in dictating system behavior, it is common for the pre-\nprompt to consume more than a thousand tokens, which means the entire context window in many\nmodern LLMs will be exhausted only with a few dozen back-and-forth messages between the user\nand system For example, a 1000 token preprompt (roughly the size of the MemGPT preprompt in\nour experiments) leaves space for only about 60 remaining messages when using 4K context models\nsuch as llama-2 orgpt-3.5-turbo (see Table 1 for more examples) In settings where the\nuser is expected to communicate frequently with the system (for example, virtual companions or\npersonalized assistants), it is easy to imagine exceeding the maximum conversation length even for\nmodels with 100k context windows in a matter of days (or potentially hours) Resursive summariza-\ntion (Wu et al., 2021b) is a simple way to address overflowing context windows, however, recursive\nsummarization is inherently lossy and eventually leads to large holes in the memory of the system\n(as we demonstrate in Section 3)", "summary": "MemGPT is an OS-inspired LLM system that enables unbounded context by managing its own memory. It uses a multi-level memory architecture with main context (in-context information) and external context (out-of-context data). The main context holds the fixed-context window for inference, while the external context must be explicitly moved into the main context. MemGPT provides function calls for the LLM processor to manage its memory without user intervention. The preprompt, which dictates system behavior, can consume a significant portion of the main context tokens, limiting the conversation length. Recursive summarization is a potential solution but leads to memory loss.", "clean_entities": [], "dirty_entities": ["Entities: LLM", "MemGPT", "MemGPT OS", "agent", "process", "memory-hierarchy", "OS functions", "event-based control flow", "document analysis", "conversational agents", "persona consistency", "long-term memory", "main context", "external context", "LLM processor", "system message", "preprompt", "personas", "complex tasks", "instructions", "back-and-forth messages", "user", "virtual companions", "personalized assistants", "recursive summarization", "memory.", "", "Keywords: illusion", "virtual memory", "context length", "LLM OS", "MemGPT", "historical data", "in-context", "finite context", "unbounded context", "memory types", "fixed-context window", "main memory", "physical memory", "RAM", "disk memory", "disk storage", "inference", "function calls", "user intervention", "LLM inputs", "system message", "conversation data", "preprompt", "personas", "complex instructions", "conversation length", "virtual companions", "personalized assistants", "overflowing context windows", "recursive summarization", "memory holes.", "", "Phrases: LLM processor", "context awareness", "long-term memory", "finite context", "fixed-context window", "system message", "preprompt", "conversation data", "complex instructions", "conversation length", "overflowing context windows", "memory holes.", "", "References: MemGPT MemGPT", "OS page fault", "Figure 1", "MemGPT system", "LLMs", "modern LLMs", "MemGPT preprompt", "llama-1 model family", "llama-2 model family", "gpt-3.5-turbo API", "gpt-4 API", "gpt-3.5-turbo-16k API", "gpt-4-32k Limited API", "claude-instant-1 Limited API", "claude-2 Limited API", "Touvron et al.", "2023", "SillyTavern", "2023", "Liu et al.", "2023b", "Wu et al.", "2021b.", "", "Abstract Concepts: virtual memory", "context management", "memory hierarchy", "context awareness", "persona consistency", "long-term memory", "context windows", "recursive summarization", "lossy memory."], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "MemGPT architecture and memory management", "justification": "The summary provides an overview of MemGPT's multi-level memory architecture and how it manages its own memory."}, {"topic": "Main context and external context in MemGPT", "justification": "The summary explains the distinction between the main context (in-context information) and the external context (out-of-context data) in MemGPT."}, {"topic": "Function calls for memory management in MemGPT", "justification": "The summary mentions that MemGPT provides function calls for the LLM processor to manage its memory without user intervention."}, {"topic": "Limitations of MemGPT's conversation length due to preprompt", "justification": "The summary discusses how the preprompt, which dictates system behavior, can consume a significant portion of the main context tokens, limiting the conversation length."}, {"topic": "Memory loss in recursive summarization as a potential solution", "justification": "The summary mentions that recursive summarization is a potential solution but leads to memory loss. This topic explores the trade-off between summarization and memory usage."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does MemGPT manage its memory to enable unbounded context?"}, {"question_type": "Analytical Question", "question": "What are the advantages and disadvantages of using a multi-level memory architecture in MemGPT?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a scenario where MemGPT is used in a real-time conversation. How could the limitation of conversation length due to the preprompt be overcome?"}, {"question_type": "Contextual/Relational Question", "question": "How does the use of recursive summarization in MemGPT impact its ability to retain memory?"}, {"question_type": "User-Interactive Question", "question": "As a user, how would you feel about MemGPT automatically managing its memory without your intervention? How could this feature enhance or hinder your experience?"}], "knowledge_triplets": [{"subject": "LLM", "relationship": "manages", "target": "context"}, {"subject": "MemGPT", "relationship": "enables", "target": "LLM"}, {"subject": "agent", "relationship": "modify", "target": "context"}, {"subject": "process", "relationship": "access", "target": "virtual memory"}, {"subject": "MemGPT", "relationship": "handles", "target": "unbounded context"}, {"subject": "MemGPT", "relationship": "evaluates", "target": "existing LLMs"}, {"subject": "MemGPT", "relationship": "outperforms", "target": "existing LLM-based approaches"}, {"subject": "MemGPT", "relationship": "implements", "target": "OS-inspired LLM system"}, {"subject": "MemGPT", "relationship": "teaches", "target": "LLMs"}, {"subject": "MemGPT", "relationship": "delineates", "target": "memory architecture"}, {"subject": "main context", "relationship": "considered", "target": "in-context"}, {"subject": "external context", "relationship": "holds", "target": "out-of-context data"}, {"subject": "MemGPT", "relationship": "provides", "target": "function calls"}, {"subject": "LLM processor", "relationship": "uses", "target": "function calls"}, {"subject": "MemGPT", "relationship": "refers", "target": "LLM inputs"}, {"subject": "main context", "relationship": "used", "target": "hold system message"}, {"subject": "main context", "relationship": "used", "target": "hold conversation data"}, {"subject": "preprompt", "relationship": "enables", "target": "system to adopt personas"}, {"subject": "preprompt", "relationship": "consumes", "target": "tokens"}, {"subject": "preprompt", "relationship": "dictates", "target": "system behavior"}, {"subject": "recursive summarization", "relationship": "addresses", "target": "overflowing context windows"}, {"subject": "recursive summarization", "relationship": "leads to", "target": "holes in system memory"}, {"subject": "LLM", "relationship": "manages", "target": "context"}, {"subject": "LLM", "relationship": "retrieves", "target": "historical data"}, {"subject": "LLM", "relationship": "modifies", "target": "context"}, {"subject": "process", "relationship": "accesses", "target": "virtual memory"}, {"subject": "MemGPT", "relationship": "has", "target": "memory-hierarchy"}, {"subject": "MemGPT", "relationship": "has", "target": "OS functions"}, {"subject": "MemGPT", "relationship": "has", "target": "event-based control flow"}, {"subject": "MemGPT", "relationship": "handles", "target": "unbounded context"}, {"subject": "LLMs", "relationship": "have", "target": "finite context windows"}, {"subject": "MemGPT", "relationship": "overcomes", "target": "limitations of finite context"}, {"subject": "MemGPT", "relationship": "outperforms", "target": "existing LLM-based approaches"}, {"subject": "MemGPT", "relationship": "implements", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "teaches", "target": "LLMs"}, {"subject": "LLMs", "relationship": "manage", "target": "memory"}, {"subject": "MemGPT", "relationship": "delineates", "target": "memory architecture"}, {"subject": "main context", "relationship": "is", "target": "fixed-context window"}, {"subject": "external context", "relationship": "is", "target": "disk memory"}, {"subject": "MemGPT", "relationship": "provides", "target": "function calls"}, {"subject": "LLM processor", "relationship": "uses", "target": "function calls"}, {"subject": "main context", "relationship": "holds", "target": "system message"}, {"subject": "main context", "relationship": "holds", "target": "conversation data"}, {"subject": "preprompt", "relationship": "enables", "target": "system to adopt various personas"}, {"subject": "preprompt", "relationship": "dictates", "target": "system behavior"}, {"subject": "preprompt", "relationship": "consumes", "target": "more than a thousand tokens"}, {"subject": "conversation length", "relationship": "exceeds", "target": "maximum conversation length"}, {"subject": "recursive summarization", "relationship": "addresses", "target": "overflowing context windows"}, {"subject": "recursive summarization", "relationship": "leads to", "target": "memory holes"}, {"subject": "LLM", "relationship": "manages", "target": "context"}, {"subject": "MemGPT", "relationship": "enables", "target": "LLM"}, {"subject": "agent", "relationship": "modify", "target": "context"}, {"subject": "process", "relationship": "access", "target": "virtual memory"}, {"subject": "MemGPT", "relationship": "handles", "target": "unbounded context"}, {"subject": "MemGPT", "relationship": "evaluates", "target": "existing LLMs"}, {"subject": "MemGPT", "relationship": "outperforms", "target": "existing LLM-based approaches"}, {"subject": "MemGPT", "relationship": "implements", "target": "OS-inspired LLM system"}, {"subject": "MemGPT", "relationship": "teaches", "target": "LLMs"}, {"subject": "MemGPT", "relationship": "delineates", "target": "memory architecture"}, {"subject": "main context", "relationship": "considered", "target": "in-context"}, {"subject": "external context", "relationship": "holds", "target": "out-of-context data"}, {"subject": "MemGPT", "relationship": "provides", "target": "function calls"}, {"subject": "LLM processor", "relationship": "uses", "target": "function calls"}, {"subject": "MemGPT", "relationship": "refers", "target": "LLM inputs"}, {"subject": "main context", "relationship": "used", "target": "hold system message"}, {"subject": "main context", "relationship": "used", "target": "hold conversation data"}, {"subject": "preprompt", "relationship": "enables", "target": "system to adopt personas"}, {"subject": "preprompt", "relationship": "consumes", "target": "tokens"}, {"subject": "preprompt", "relationship": "dictates", "target": "system behavior"}, {"subject": "recursive summarization", "relationship": "addresses", "target": "overflowing context windows"}, {"subject": "recursive summarization", "relationship": "leads to", "target": "holes in system memory"}], "timestamp": "2024-01-14T17:27:06.839204"}, {"file_id": "2310.08560", "article": "Chunk # 2.\nThis motivates the need for a more comprehensive way to manage\nmemory for conversational systems that are meant to be used in long-term settings In our experiments on multi-session chat and document analysis, we further divide main context\ninto three components: system instructions , which hold the base LLM instructions (e.g., informa-\ntion describing MemGPT functions and control flow to the LLM), conversational context , which\nholds a first-in-first-out (FIFO) queue of recent event history (e.g., messages between the agent and\nuser), and working context , which serves as a working memory scratchpad for the agent System\ninstructions are read-only and pinned to main context (they do not change during the lifetime of the\nMemGPT agent), conversational context is read-only with a special eviction policy (if the queue\nreaches a certain size, a portion of the front is truncated or compressed via recursive summariza-\ntion), and working context is writeable by the LLM processor via function calls Combined, the\nthree parts of main context cannot exceed the underlying LLM processors\u2019s maximum context size,\nand in practice we limit the size of conversational context and working context to a fixed constant\ndetermined by the processor\u2019s context window and the system instructions length 3Preprint\nHello Chad, welcome I\u2019m excited to embark on this journey with you As a PhD student in\nComputer Science, I can only imagine the fascinating ideas you\u2019re juggling Can you share\nwhat you\u2019re currently working on I am all ears!MemGPT\nI took the day off today, my mom Brenda baked me a birthday cake It was my favorite -\nchocolate lava!User October 11, 2023\nworking context append(\u2019Birthday: 11th October \\nFavorite\ncake: Chocolate Lava made by mom Brenda\u2019)\nHappy Birthday, Chad Nothing like a special treat to make the day sweeter, your\nmom Brenda\u2019s chocolate lava cake sounds divine We all need these small joys, don\u2019t we If\nyou don\u2019t mind sharing, how old are you today Let\u2019s make today\u2019s chat another cherished\nmemory for you!MemGPT\nFigure 2: An example conversation snippet where MemGPT writes details from conversation to\nworking context without a memory warning from the system 2.2 E XTERNAL CONTEXT\nExternal context refers to out-of-context storage that lies outside the context window of the LLM\nprocessor, analogous to disk memory (i.e disk storage) in OSes Information in external context is\nnot immediately visible to the LLM processor, however, it can be brought into main context through\nappropriate function calls In practice, the underlying storage in external context can take various\nforms which can be configured for specific tasks: for example, for conversational agents it may be\ndesireable to store full chat logs between the user and agent (that MemGPT can access at a later\ndate), and for document analysis large document collections can be stored inside external context\nthat MemGPT can bring into restricted main context via paginated function calls to disk In our experiments, using MemGPT for multi-session chat and document analysis, we use databases\nto store text documents and embeddings/vectors, provide several ways for the LLM processor to\nquery external context: timestamp-based search, text-based search, and embedding-based search We make a distinction between two types of external context: recall storage , which stores the entire\nhistory of events processed by the LLM processor (in essense the full uncompressed queue from\nactive memory), and archival storage , which serves as a general read-write datastore that the agent\ncan utilize as overflow for the in-context read-write core memory In the context of conversational\nagents, archival storage allows MemGPT to store facts, experiences, preferences, etc about the\nagent or user beyond the strict token limit of main context, and search over recall storage allows\nthe MemGPT to find past interactions related to a particular query or within a specific time period In the context of document analysis, archival storage can be used to search over (and add to) an\nexpansive document database 2.3 S ELF-DIRECTED EDITING AND RETRIEVAL\nMemGPT orchestrates data movement between main context and external context via function calls\nthat are generated by the LLM processor Memory edits and retrieval are entirely self-directed:\nMemGPT autonomously updates and searches through its own memory based on the current con-\ntext For instance, it can decide when to move items between contexts (Figure 2) and modify its\nmain context to better reflect its evolving understanding of its current objectives and responsibilities\n(Figure 4) We implement self-directed editing and retrieval by providing explicit instructions within\nthe preprompt that guide the system on how to interact with its memory systems These instructions\ncomprise two main components: (1) a detailed description of the memory hierarchy and their re-\nspective utilities, and (2) a function schema (complete with their natural language descriptions) that\nthe system can call to access or modify its memory 4Preprint\nHello Chad", "summary": "Revised Summary (Iteration 3): MemGPT and LLM processors efficiently process information in conversational systems. Chad and Brenda manage memory to ensure effective multi-session chat and document analysis. The system utilizes a memory hierarchy, including system instructions, conversational context, and working context. External context stores information outside the immediate context, allowing for recall storage and archival storage. The SPR enables efficient compression of information. Self-directed editing and retrieval facilitate memory updates and searches. The function schema provides natural language descriptions for accessing and modifying memory. Conversational context, working memory, evolving understanding, and current objectives guide the system's actions. The main context size is a fixed constant in the underlying LLM processors. External context refers to out-of-context storage. Information in external context is not immediately visible. External context can be brought into the main context. Databases store text documents and embeddings/vectors. Recall storage stores the entire history of events. Archival storage serves as a general read-write datastore. Memory edits and retrieval are entirely self-directed. The memory hierarchy includes working memory. The system can call a function schema. Memory management is crucial for efficient operation. Evolving understanding and current objectives guide memory usage.", "clean_entities": ["MemGPT", "LLM", "Chad", "Brenda", "comprehensive way", "manage memory", "conversational systems", "long-term settings", "multi-session chat", "document analysis", "system instructions", "conversational context", "working context", "main context", "LLM processor", "context size", "fixed constant", "external context", "disk memory", "storage", "chat logs", "document collections", "recall storage", "archival storage", "read-write datastore", "token limit", "self-directed editing", "retrieval", "memory hierarchy", "function schema", "natural language descriptions", "memory for conversational systems", "long-term settings", "multi-session chat and document analysis", "system instructions", "underlying LLM processors's maximum context size", "external context refers to out-of-context storage", "information in external context is not immediately visible", "external context can be brought into main context", "databases to store text documents and embeddings/vectors", "recall storage stores the entire history of events", "archival storage serves as a general read-write datastore", "self-directed editing and retrieval", "memory edits and retrieval are entirely self-directed", "explicit instructions within the preprompt", "memory hierarchy and their respective utilities", "function schema that the system can call", "Figure 2", "Figure 4", "Memory management", "Conversational context", "Working memory", "Evolving understanding", "Current objectives and responsibilities"], "dirty_entities": ["Entities:", "", "Keywords:", "", "Key Phrases:", "conversational context", "working context", "", "References:", "", "Abstract Concepts:", "", "Output: MemGPT", "LLM", "Chad", "Brenda", "comprehensive way", "manage memory", "conversational systems", "long-term settings", "multi-session chat", "document analysis", "system instructions", "conversational context", "working context", "main context", "LLM processor", "context size", "fixed constant", "external context", "disk memory", "storage", "chat logs", "document collections", "recall storage", "archival storage", "read-write datastore", "token limit", "self-directed editing", "retrieval", "memory hierarchy", "function schema", "natural language descriptions", "memory for conversational systems", "underlying LLM processors's maximum context size", "databases to store text documents and embeddings/vectors", "information in external context is not immediately visible", "external context can be brought into main context", "recall storage stores the entire history of events", "archival storage serves as a general read-write datastore", "self-directed editing and retrieval", "memory edits and retrieval are entirely self-directed", "explicit instructions within the preprompt", "memory hierarchy and their respective utilities", "function schema that the system can call."], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "MemGPT and LLM processors in conversational systems", "justification": "The summary highlights the efficient processing of information in conversational systems using MemGPT and LLM processors."}, {"topic": "Memory management in conversational systems", "justification": "The summary emphasizes the importance of memory management for effective multi-session chat and document analysis in conversational systems."}, {"topic": "Memory hierarchy in conversational systems", "justification": "The summary mentions the memory hierarchy used in conversational systems, including system instructions, conversational context, working context, and external context."}, {"topic": "External context in conversational systems", "justification": "The summary explains the concept of external context and its role in storing information outside the immediate context in conversational systems."}, {"topic": "SPR (Storage, Processing, and Retrieval) in conversational systems", "justification": "The summary mentions the SPR technique used for efficient compression of information in conversational systems."}, {"topic": "Self-directed editing and retrieval in memory management", "justification": "The summary highlights the ability of the system to perform self-directed editing and retrieval for memory updates and searches."}, {"topic": "Function schema in memory management", "justification": "The summary mentions the use of function schema for natural language descriptions to access and modify memory in conversational systems."}, {"topic": "Databases in memory management", "justification": "The summary mentions the use of databases to store text documents and embeddings/vectors in memory management."}, {"topic": "Recall storage and archival storage in memory management", "justification": "The summary explains the concepts of recall storage (storing the entire history of events) and archival storage (general read-write datastore) in memory management."}, {"topic": "Working memory in the memory hierarchy", "justification": "The summary includes working memory as a component of the memory hierarchy in conversational systems."}, {"topic": "Role of evolving understanding and current objectives in memory usage", "justification": "The summary mentions how evolving understanding and current objectives guide the usage of memory in conversational systems."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How do MemGPT and LLM processors efficiently process information in conversational systems?"}, {"question_type": "Analytical Question", "question": "What are the different components of the memory hierarchy utilized by Chad and Brenda in managing memory for effective multi-session chat and document analysis?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine you are using a conversational system with memory management capabilities. How would you utilize the memory hierarchy to ensure efficient recall and storage of information?"}, {"question_type": "Contextual/Relational Question", "question": "How does the external context in the memory hierarchy differ from the conversational and working context, and how does it contribute to the overall memory management process?"}, {"question_type": "User-Interactive Question", "question": "As a user of a conversational system, how would you prefer the memory management to be implemented to enhance your experience and facilitate efficient information retrieval?"}], "knowledge_triplets": [{"subject": "conversational systems", "relationship": "motivates", "target": "need"}, {"subject": "memory", "relationship": "manage", "target": "comprehensive way"}, {"subject": "conversational systems", "relationship": "meant to be used", "target": "long-term settings"}, {"subject": "experiments", "relationship": "multi-session chat and document analysis", "target": "divide"}, {"subject": "main context", "relationship": "three components", "target": "system instructions"}, {"subject": "main context", "relationship": "three components", "target": "conversational context"}, {"subject": "main context", "relationship": "three components", "target": "working context"}, {"subject": "system instructions", "relationship": "hold", "target": "base LLM instructions"}, {"subject": "conversational context", "relationship": "hold", "target": "FIFO queue"}, {"subject": "working context", "relationship": "serve as", "target": "working memory scratchpad"}, {"subject": "system instructions", "relationship": "read-only", "target": "pinned to main context"}, {"subject": "conversational context", "relationship": "read-only", "target": "eviction policy"}, {"subject": "working context", "relationship": "writeable", "target": "LLM processor"}, {"subject": "main context", "relationship": "cannot exceed", "target": "LLM processors\u2019s maximum context size"}, {"subject": "conversational context", "relationship": "limit size", "target": "fixed constant"}, {"subject": "working context", "relationship": "limit size", "target": "fixed constant"}, {"subject": "working context", "relationship": "append", "target": "Birthday: 11th October \\nFavorite cake: Chocolate Lava made by mom Brenda"}, {"subject": "mom Brenda", "relationship": "baked", "target": "birthday cake"}, {"subject": "mom Brenda", "relationship": "chocolate lava cake", "target": "sounds divine"}, {"subject": "mom Brenda", "relationship": "chocolate lava cake", "target": "favorite"}, {"subject": "small joys", "relationship": "need", "target": "all"}, {"subject": "today", "relationship": "chat", "target": "cherished memory"}, {"subject": "today", "relationship": "chat", "target": "birthday"}, {"subject": "Chad", "relationship": "old", "target": "today"}, {"subject": "MemGPT", "relationship": "writes", "target": "details from conversation"}, {"subject": "MemGPT", "relationship": "memory warning", "target": "system"}, {"subject": "external context", "relationship": "out-of-context storage", "target": "disk memory"}, {"subject": "external context", "relationship": "not immediately visible", "target": "LLM processor"}, {"subject": "external context", "relationship": "brought into main context", "target": "function calls"}, {"subject": "external context", "relationship": "various forms", "target": "configured for specific tasks"}, {"subject": "conversational agents", "relationship": "store", "target": "full chat logs"}, {"subject": "MemGPT", "relationship": "access", "target": "chat logs"}, {"subject": "document analysis", "relationship": "large document collections", "target": "store inside external context"}, {"subject": "MemGPT", "relationship": "bring into restricted main context", "target": "paginated function calls"}, {"subject": "MemGPT", "relationship": "multi-session chat and document analysis", "target": "use databases"}, {"subject": "MemGPT", "relationship": "query", "target": "external context"}, {"subject": "MemGPT", "relationship": "timestamp-based search", "target": "external context"}, {"subject": "MemGPT", "relationship": "text-based search", "target": "external context"}, {"subject": "MemGPT", "relationship": "embedding-based search", "target": "external context"}, {"subject": "external context", "relationship": "recall storage", "target": "stores entire history of events"}, {"subject": "external context", "relationship": "archival storage", "target": "read-write datastore"}, {"subject": "archival storage", "relationship": "MemGPT", "target": "store facts, experiences, preferences"}, {"subject": "MemGPT", "relationship": "search over recall storage", "target": "find past interactions"}, {"subject": "MemGPT", "relationship": "search over recall storage", "target": "particular query"}, {"subject": "MemGPT", "relationship": "search over recall storage", "target": "specific time period"}, {"subject": "document analysis", "relationship": "archival storage", "target": "search over document database"}, {"subject": "MemGPT", "relationship": "data movement", "target": "main context"}, {"subject": "MemGPT", "relationship": "data movement", "target": "external context"}, {"subject": "MemGPT", "relationship": "function calls", "target": "generated by LLM processor"}, {"subject": "MemGPT", "relationship": "memory edits", "target": "self-directed"}, {"subject": "MemGPT", "relationship": "retrieval", "target": "self-directed"}, {"subject": "MemGPT", "relationship": "move items", "target": "contexts"}, {"subject": "MemGPT", "relationship": "modify", "target": "main context"}, {"subject": "MemGPT", "relationship": "reflect", "target": "evolving understanding"}, {"subject": "MemGPT", "relationship": "current objectives", "target": "responsibilities"}, {"subject": "MemGPT", "relationship": "self-directed editing", "target": "retrieval"}, {"subject": "preprompt", "relationship": "explicit instructions", "target": "guide system"}, {"subject": "preprompt", "relationship": "memory hierarchy", "target": "respective utilities"}, {"subject": "preprompt", "relationship": "function schema", "target": "system can call"}, {"subject": "conversational systems", "relationship": "manage memory", "target": "comprehensive way"}, {"subject": "multi-session chat", "relationship": "document analysis", "target": "experiments"}, {"subject": "system instructions", "relationship": "main context", "target": "holds"}, {"subject": "conversational context", "relationship": "main context", "target": "holds"}, {"subject": "working context", "relationship": "main context", "target": "serves as"}, {"subject": "main context", "relationship": "LLM processor", "target": "cannot exceed"}, {"subject": "conversational context", "relationship": "working context", "target": "limit size"}, {"subject": "working context", "relationship": "LLM processor", "target": "writeable"}, {"subject": "main context", "relationship": "LLM processor", "target": "maximum context size"}, {"subject": "external context", "relationship": "LLM processor", "target": "lies outside"}, {"subject": "external context", "relationship": "main context", "target": "bring into"}, {"subject": "external context", "relationship": "conversational agents", "target": "store full chat logs"}, {"subject": "external context", "relationship": "document analysis", "target": "store text documents"}, {"subject": "recall storage", "relationship": "LLM processor", "target": "stores the entire history"}, {"subject": "archival storage", "relationship": "LLM processor", "target": "serves as"}, {"subject": "archival storage", "relationship": "conversational agents", "target": "allows MemGPT to store"}, {"subject": "recall storage", "relationship": "MemGPT", "target": "search over"}, {"subject": "archival storage", "relationship": "document analysis", "target": "can be used to search over"}, {"subject": "MemGPT", "relationship": "main context", "target": "updates and searches"}, {"subject": "main context", "relationship": "MemGPT", "target": "modify"}, {"subject": "self-directed editing", "relationship": "retrieval", "target": "MemGPT orchestrates"}, {"subject": "LLM processor", "relationship": "memory systems", "target": "interact with"}, {"subject": "system instructions", "relationship": "memory systems", "target": "guide the system"}, {"subject": "memory hierarchy", "relationship": "system instructions", "target": "detailed description"}, {"subject": "function schema", "relationship": "system instructions", "target": "call to access or modify"}, {"subject": "conversational systems", "relationship": "motivates", "target": "need"}, {"subject": "memory", "relationship": "manage", "target": "comprehensive way"}, {"subject": "conversational systems", "relationship": "meant to be used", "target": "long-term settings"}, {"subject": "experiments", "relationship": "multi-session chat and document analysis", "target": "divide"}, {"subject": "main context", "relationship": "three components", "target": "system instructions"}, {"subject": "main context", "relationship": "three components", "target": "conversational context"}, {"subject": "main context", "relationship": "three components", "target": "working context"}, {"subject": "system instructions", "relationship": "hold", "target": "base LLM instructions"}, {"subject": "conversational context", "relationship": "hold", "target": "FIFO queue"}, {"subject": "working context", "relationship": "serve as", "target": "working memory scratchpad"}, {"subject": "system instructions", "relationship": "read-only", "target": "pinned to main context"}, {"subject": "conversational context", "relationship": "read-only", "target": "eviction policy"}, {"subject": "working context", "relationship": "writeable", "target": "LLM processor"}, {"subject": "main context", "relationship": "cannot exceed", "target": "LLM processors\u2019s maximum context size"}, {"subject": "conversational context", "relationship": "limit size", "target": "fixed constant"}, {"subject": "working context", "relationship": "limit size", "target": "fixed constant"}, {"subject": "working context", "relationship": "append", "target": "Birthday: 11th October \\nFavorite cake: Chocolate Lava made by mom Brenda"}, {"subject": "mom Brenda", "relationship": "baked", "target": "birthday cake"}, {"subject": "mom Brenda", "relationship": "chocolate lava cake", "target": "sounds divine"}, {"subject": "mom Brenda", "relationship": "chocolate lava cake", "target": "favorite"}, {"subject": "small joys", "relationship": "need", "target": "all"}, {"subject": "today", "relationship": "chat", "target": "cherished memory"}, {"subject": "today", "relationship": "chat", "target": "birthday"}, {"subject": "Chad", "relationship": "old", "target": "today"}, {"subject": "MemGPT", "relationship": "writes", "target": "details from conversation"}, {"subject": "MemGPT", "relationship": "memory warning", "target": "system"}, {"subject": "external context", "relationship": "out-of-context storage", "target": "disk memory"}, {"subject": "external context", "relationship": "not immediately visible", "target": "LLM processor"}, {"subject": "external context", "relationship": "brought into main context", "target": "function calls"}, {"subject": "external context", "relationship": "various forms", "target": "configured for specific tasks"}, {"subject": "conversational agents", "relationship": "store", "target": "full chat logs"}, {"subject": "MemGPT", "relationship": "access", "target": "chat logs"}, {"subject": "document analysis", "relationship": "large document collections", "target": "store inside external context"}, {"subject": "MemGPT", "relationship": "bring into restricted main context", "target": "paginated function calls"}, {"subject": "MemGPT", "relationship": "multi-session chat and document analysis", "target": "use databases"}, {"subject": "MemGPT", "relationship": "query", "target": "external context"}, {"subject": "MemGPT", "relationship": "timestamp-based search", "target": "external context"}, {"subject": "MemGPT", "relationship": "text-based search", "target": "external context"}, {"subject": "MemGPT", "relationship": "embedding-based search", "target": "external context"}, {"subject": "external context", "relationship": "recall storage", "target": "stores entire history of events"}, {"subject": "external context", "relationship": "archival storage", "target": "read-write datastore"}, {"subject": "archival storage", "relationship": "MemGPT", "target": "store facts, experiences, preferences"}, {"subject": "MemGPT", "relationship": "search over recall storage", "target": "find past interactions"}, {"subject": "MemGPT", "relationship": "search over recall storage", "target": "particular query"}, {"subject": "MemGPT", "relationship": "search over recall storage", "target": "specific time period"}, {"subject": "document analysis", "relationship": "archival storage", "target": "search over document database"}, {"subject": "MemGPT", "relationship": "data movement", "target": "main context"}, {"subject": "MemGPT", "relationship": "data movement", "target": "external context"}, {"subject": "MemGPT", "relationship": "function calls", "target": "generated by LLM processor"}, {"subject": "MemGPT", "relationship": "memory edits", "target": "self-directed"}, {"subject": "MemGPT", "relationship": "retrieval", "target": "self-directed"}, {"subject": "MemGPT", "relationship": "move items", "target": "contexts"}, {"subject": "MemGPT", "relationship": "modify", "target": "main context"}, {"subject": "MemGPT", "relationship": "reflect", "target": "evolving understanding"}, {"subject": "MemGPT", "relationship": "current objectives", "target": "responsibilities"}, {"subject": "MemGPT", "relationship": "self-directed editing", "target": "retrieval"}, {"subject": "preprompt", "relationship": "explicit instructions", "target": "guide system"}, {"subject": "preprompt", "relationship": "memory hierarchy", "target": "respective utilities"}, {"subject": "preprompt", "relationship": "function schema", "target": "system can call"}, {"subject": "conversational systems", "relationship": "manage memory", "target": "comprehensive way"}, {"subject": "multi-session chat", "relationship": "document analysis", "target": "experiments"}, {"subject": "system instructions", "relationship": "main context", "target": "holds"}, {"subject": "conversational context", "relationship": "main context", "target": "holds"}, {"subject": "working context", "relationship": "main context", "target": "serves as"}, {"subject": "main context", "relationship": "LLM processor", "target": "cannot exceed"}, {"subject": "conversational context", "relationship": "working context", "target": "limit size"}, {"subject": "working context", "relationship": "LLM processor", "target": "writeable"}, {"subject": "main context", "relationship": "LLM processor", "target": "maximum context size"}, {"subject": "external context", "relationship": "LLM processor", "target": "lies outside"}, {"subject": "external context", "relationship": "main context", "target": "bring into"}, {"subject": "external context", "relationship": "conversational agents", "target": "store full chat logs"}, {"subject": "external context", "relationship": "document analysis", "target": "store text documents"}, {"subject": "recall storage", "relationship": "LLM processor", "target": "stores the entire history"}, {"subject": "archival storage", "relationship": "LLM processor", "target": "serves as"}, {"subject": "archival storage", "relationship": "conversational agents", "target": "allows MemGPT to store"}, {"subject": "recall storage", "relationship": "MemGPT", "target": "search over"}, {"subject": "archival storage", "relationship": "document analysis", "target": "can be used to search over"}, {"subject": "MemGPT", "relationship": "main context", "target": "updates and searches"}, {"subject": "main context", "relationship": "MemGPT", "target": "modify"}, {"subject": "self-directed editing", "relationship": "retrieval", "target": "MemGPT orchestrates"}, {"subject": "LLM processor", "relationship": "memory systems", "target": "interact with"}, {"subject": "system instructions", "relationship": "memory systems", "target": "guide the system"}, {"subject": "memory hierarchy", "relationship": "system instructions", "target": "detailed description"}, {"subject": "function schema", "relationship": "system instructions", "target": "call to access or modify"}], "timestamp": "2024-01-14T17:28:23.930384"}, {"file_id": "2310.08560", "article": "Chunk # 3.\nIt\u2019s a pleasure to finally have a conversation with you I\u2019m Samantha I\nunderstand that you\u2019re studying computer science and have a keen interest in pretty dynamic\nareas like Formula 1 and sailing What in particular draws you to these interests?MemGPT\nspeed of course, the thrill and the adrenalineUser\nWarning: the conversation history will soon reach its maximum length and be trimmed Make sure to save any important information from the conversation to your memory before\nit is removed.System\nworking context append(\u2019Key Personality Trait: Enjoys\nhigh-speed, adrenaline-rush activities like Formula 1 racing\nand intense gaming sessions in CSGO.\u2019)MemGPT\nFigure 3: An example conversation snippet where MemGPT writes details from conversation to\nmemory after it receives a system alert about memory pressure During each inference cycle, LLM processor takes main context (concatenated into a single string) as\ninput, and generates an output string This output string is parsed by MemGPT to ensure correctness,\nand if the parser validates the function arguments the function is executed The results, including\nany runtime errors that occur (e.g trying to add to main context when it is already at maximum\ncapacity), are then fed back to the processor by MemGPT This feedback loop enables the system\nto learn from its actions and adjust its behavior accordingly Awareness of context limits is a key\naspect in making the self-editing mechanism work effectively, to this end MemGPT prompts the\nprocessor with warnings regarding token limitations to guide its memory management decisions\n(Figure 3) Additionally, our memory retrieval mechanisms are designed to be cognizant of these\ntoken constraints and implement pagination to prevent retrieval calls from overflowing the context\nwindow 2.4 C ONTROL FLOW AND FUNCTION CHAINING\nIn MemGPT, events trigger LLM inference: events are generalized inputs to MemGPT and can con-\nsist of user messages (in chat applications), system messages (e.g main context capacity warnings),\nuser interactions (e.g an alert that a user just logged in, or an alert that they finished uploading\na document), and timed events that are run on a regular schedule (allowing MemGPT to run \u2018un-\nprompted\u2019 without user intervention) MemGPT processes events with a parser to convert them into\nplain text messages that can be appended to main context and eventually be fed as input into the\nLLM processor Many practical tasks require calling multiple functions in sequence, for example, navigating through\nmultiple pages of results from a single query or collating data from different documents in main\ncontext from separate queries Function chaining allows MemGPT to execute multiple function\ncalls sequentially before returning control to the user In MemGPT, functions can be called with\na special flag that requests control be immediately returned to the processor after the requested\nfunction completes execution If this flag is present, MemGPT will add the function output to\nmain context and (as opposed to pausing processor execution) If this flag is not present (a yield ),\nMemGPT will not run the LLM processor until the next external event trigger (e.g a user message\nor scheduled interrupt) 5Preprint\nWelcome back Fancy a chat about horror movies Any particular film you\u2019ve watched\nrecently that stuck with you?MemGPT\nI actually don\u2019t like horror movies I\u2019m more into romantic comedy.User\nworking context.replace(\u2019I watch horror movies.\u2019,\u2019I like\nromantic comedies.\u2019)\nMy apologies for the mix-up earlier Romantic comedies are a delightful genre, full\nof laughter and heartfelt moments Do you have a favorite romantic comedy?MemGPT\nFigure 4: An example conversation snippet where MemGPT corrects information about the user by\nwriting to main context (and replacing a section of text in working context) 3 E XPERIMENTS\nWe assess MemGPT in two long-context domains: conversational agents and document analysis For conversational agents, we expand the existing Multi-Session Chat dataset Xu et al (2021) and\nintroduce two new dialogue tasks that evaluate an agent\u2019s ability to retain knowledge across long\nconversations For document analysis, we benchmark MemGPT on existing tasks from Liu et al (2023a) for question answering and key-value retrieval over lengthy documents We also propose\na new nested key-value retrieval task requiring collating information across multiple data sources,\nwhich tests the ability of an agent to collate information from multiple data sources (multi-hop\nretrieval) We publicly release our augmented MSC dataset, nested KV retrieval dataset, and a\ndataset of embeddings for 20M Wikipedia articles to facilitate future research Our code for the full\nconversational and document analysis benchmarks is available at https://memgpt.ai 3.1 M EMGPT FOR CONVERSATIONAL AGENTS\nConversational agents like virtual companions and personalized assistants aim to engage users in\nnatural, long-term interactions, potentially spanning weeks, months, or even years This creates\nchallenges for models with fixed-length contexts, which can only reference a limited history of the\nconversation An \u2018infinite context\u2019 agent should seamlessly handle continuous exchanges without\nboundary or reset", "summary": "Revised Summary: Samantha, a person with a keen interest in dynamic areas, is drawn to Formula 1 racing and sailing for the adrenaline rush they provide. She also enjoys intense gaming sessions in CSGO. While she doesn't like horror movies, Samantha finds romantic comedies to be a delightful genre, full of laughter and heartfelt moments. She wonders if you have a favorite romantic comedy. Samantha is attracted to adrenaline rush activities, thrill, speed, romance, and comedy. MemGPT, a language model, processes events and has a memory mechanism for context management and learning. It can execute functions sequentially and correct information by replacing text in the working context. MemGPT is evaluated in conversational agents and document analysis tasks, showcasing its knowledge retention and document analysis capabilities.", "clean_entities": ["Samantha (Person)", "Formula 1 (Event)", "sailing (Activity)", "computer science (Field of Study)", "Formula 1 racing (Activity)", "CSGO (Game)", "horror movies (Genre)", "romantic comedy (Genre)", "laughter (Emotion)", "Samantha", "computer science", "Formula 1", "sailing", "interests", "dynamic areas", "Formula 1 racing", "intense gaming sessions", "CSGO", "horror movies", "romantic comedy", "favorite romantic comedy", "laughter", "heartfelt moments", "studying computer science", "keen interest in pretty dynamic areas", "draws you to these interests?", "Formula 1 racing and intense gaming sessions in CSGO", "I actually don't like horror movies", "Romantic comedies are a delightful genre", "Do you have a favorite romantic comedy?", "Formula 1 racing and intense gaming sessions in CSGO", "horror movies", "romantic comedy", "Adrenaline rush activities", "Thrill", "Adrenaline", "Speed", "Romance", "Comedy"], "dirty_entities": ["Entities:", "", "Keywords:", "", "Phrases:", "full of laughter and heartfelt moments", "", "References:", "", "Abstract Concepts:", "", "Final Output: Samantha", "computer science", "Formula 1", "sailing", "interests", "dynamic areas", "Formula 1 racing", "intense gaming sessions", "CSGO", "horror movies", "romantic comedy", "favorite romantic comedy", "laughter", "heartfelt moments", "adrenaline rush activities", "thrill", "adrenaline", "speed", "romance", "comedy"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "Adrenaline Rush Activities", "justification": "Samantha is drawn to Formula 1 racing, sailing, and intense gaming sessions in CSGO for the adrenaline rush they provide."}, {"topic": "Thrill and Speed", "justification": "Samantha's interest in Formula 1 racing and sailing reflects her attraction to thrill and speed."}, {"topic": "Romance", "justification": "Samantha finds romantic comedies to be a delightful genre, indicating her interest in romance."}, {"topic": "Comedy", "justification": "Samantha enjoys romantic comedies for their laughter and heartfelt moments."}, {"topic": "MemGPT", "justification": "MemGPT is mentioned as a language model with memory mechanism and knowledge retention capabilities."}, {"topic": "Context Management and Learning", "justification": "MemGPT is described as having a memory mechanism for context management and learning."}, {"topic": "Sequential Function Execution", "justification": "MemGPT is mentioned as being able to execute functions sequentially."}, {"topic": "Document Analysis", "justification": "MemGPT's capabilities in document analysis tasks are highlighted."}, {"topic": "Conversational Agents", "justification": "MemGPT's evaluation in conversational agents is mentioned, showcasing its application in this area."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How might Samantha's interest in Formula 1 racing and sailing reflect her desire for adrenaline rush activities and thrill-seeking?"}, {"question_type": "Analytical Question", "question": "How can MemGPT's memory mechanism for context management and learning enhance its ability to process events and retain knowledge?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine Samantha decides to combine her love for speed and romance by participating in a Formula 1 race with her significant other. How might this unique experience unfold?"}, {"question_type": "Contextual/Relational Question", "question": "In what ways can Samantha's attraction to intense gaming sessions and romantic comedies be related to her desire for excitement and emotional connection?"}, {"question_type": "User-Interactive Question", "question": "What other adrenaline rush activities or genres do you think Samantha might enjoy based on her interests in Formula 1 racing, sailing, and romantic comedies?"}], "knowledge_triplets": [{"subject": "Samantha", "relationship": "studying", "target": "computer science"}, {"subject": "Samantha", "relationship": "interest in", "target": "Formula 1"}, {"subject": "Samantha", "relationship": "interest in", "target": "sailing"}, {"subject": "Samantha", "relationship": "interest in", "target": "Formula 1 racing"}, {"subject": "Samantha", "relationship": "interest in", "target": "intense gaming sessions in CSGO"}, {"subject": "Samantha", "relationship": "interest in", "target": "horror movies"}, {"subject": "Samantha", "relationship": "interest in", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "draws", "target": "interests"}, {"subject": "Samantha", "relationship": "draws", "target": "Formula 1 racing and intense gaming sessions in CSGO"}, {"subject": "Samantha", "relationship": "draws", "target": "horror movies"}, {"subject": "Samantha", "relationship": "draws", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "draws", "target": "Adrenaline rush activities"}, {"subject": "Samantha", "relationship": "draws", "target": "Thrill"}, {"subject": "Samantha", "relationship": "draws", "target": "Adrenaline"}, {"subject": "Samantha", "relationship": "draws", "target": "Speed"}, {"subject": "Samantha", "relationship": "draws", "target": "Romance"}, {"subject": "Samantha", "relationship": "draws", "target": "Comedy"}, {"subject": "Samantha", "relationship": "favorite", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "favorite", "target": "laughter"}, {"subject": "Samantha", "relationship": "favorite", "target": "heartfelt moments"}, {"subject": "Samantha", "relationship": "has interest in", "target": "Formula 1"}, {"subject": "Samantha", "relationship": "has interest in", "target": "sailing"}, {"subject": "Samantha", "relationship": "has interest in", "target": "dynamic areas"}, {"subject": "Samantha", "relationship": "has interest in", "target": "Formula 1 racing"}, {"subject": "Samantha", "relationship": "has interest in", "target": "intense gaming sessions"}, {"subject": "Samantha", "relationship": "has interest in", "target": "CSGO"}, {"subject": "Samantha", "relationship": "has interest in", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "has interest in", "target": "horror movies"}, {"subject": "Samantha", "relationship": "studying", "target": "computer science"}, {"subject": "Samantha", "relationship": "interest in", "target": "Formula 1"}, {"subject": "Samantha", "relationship": "interest in", "target": "sailing"}, {"subject": "Samantha", "relationship": "interest in", "target": "Formula 1 racing"}, {"subject": "Samantha", "relationship": "interest in", "target": "intense gaming sessions in CSGO"}, {"subject": "Samantha", "relationship": "interest in", "target": "horror movies"}, {"subject": "Samantha", "relationship": "interest in", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "draws", "target": "interests"}, {"subject": "Samantha", "relationship": "draws", "target": "Formula 1 racing and intense gaming sessions in CSGO"}, {"subject": "Samantha", "relationship": "draws", "target": "horror movies"}, {"subject": "Samantha", "relationship": "draws", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "draws", "target": "Adrenaline rush activities"}, {"subject": "Samantha", "relationship": "draws", "target": "Thrill"}, {"subject": "Samantha", "relationship": "draws", "target": "Adrenaline"}, {"subject": "Samantha", "relationship": "draws", "target": "Speed"}, {"subject": "Samantha", "relationship": "draws", "target": "Romance"}, {"subject": "Samantha", "relationship": "draws", "target": "Comedy"}, {"subject": "Samantha", "relationship": "favorite", "target": "romantic comedy"}, {"subject": "Samantha", "relationship": "favorite", "target": "laughter"}, {"subject": "Samantha", "relationship": "favorite", "target": "heartfelt moments"}], "timestamp": "2024-01-14T17:29:08.563632"}, {"file_id": "2310.08560", "article": "Chunk # 4.\nWhen conversing with a user, such an agent must satisfy two key criteria:\n\u2022 Consistency - The agent should maintain conversational coherence New facts, preferences,\nand events mentioned should align with prior statements from both the user and agent \u2022 Engagement - The agent should draw on long-term knowledge about the user to personalize\nresponses Referencing prior conversations makes dialogue more natural and engaging We therefore assess our proposed model, MemGPT, on these two criteria:\n\u2022 Does MemGPT leverage its memory to improve conversation consistency Can it remem-\nber relevant facts, preferences, and events from past interactions to maintain coherence \u2022 Does MemGPT produce more engaging dialogue by taking advantage of memory Does it\nspontaneously incorporate long-range user information to personalize messages By evaluating on consistency and engagement, we can determine how well MemGPT handles the\nchallenges of long-term conversational interaction compared to fixed-context baselines Its ability\nto satisfy these criteria will demonstrate whether unbounded context provides meaningful benefits\nfor conversational agents 6Preprint\nTaylor Swift!Hey, remember that time we talked about music What was the artist you mentioned you could get into?User is asking about past conversation, recalling our discussion on music I will search my recall memory for the artist name.Showing 5 of 50 results (page 1/10):\u201cI agree Working out is a great way to burn off steam Do you like country music?\", \u201cA little bit I can get into taylor swift.\"\u201cYeah between the both of us, could probably get a country song written about our distresses...perhaps Taylor Swift could perform it.\"\u201cThat would be a chart-topper, I'm sure Something to blast while driving with the top down, maybe even in your next restoration project.\"\u201cThis sounds fun Do you have any other hobby?\u201dsearch_recall_storage('music')\nFrom the conversation history, it seems that the artist I mentioned I could get into is Taylor Swift Let me con\ufb01rm this with the user.RecallStorage\ud83e\uddd1 \ud83d\udcad\ud83e\udd16\ud83d\udd0e\ud83e\udd16\ud83d\udce3\ud83e\udd16\ud83d\udcad\ud83e\udd16\nFigure 5: Illustration of the deep memory retrieval task In the example shown, the user asks\na question that can only be answered using information from a prior session (no longer in-context) Even though the answer is not immediately answerable using the in-context information, MemGPT\ncan search through its recall storage containing prior conversations to retrieve the answer 3.1.1 D ATASET\nWe evaluate MemGPT and our fixed-context baselines on the Multi-Session Chat (MSC) dataset\nintroduced by Xu et al (2021), which contains multi-session chat logs generated by human labelers,\neach of whom was asked to play a consistent persona for the duration of all sessions Each multi-\nsession chat in MSC has five total sessions, and each session consists of a roughly a dozen messages As part of our consistency experiments, we created a new session (session 6) that contains a single\nquestion-answer response pair between the same two personas 3.1.2 D EEP MEMORY RETRIEVAL TASK (CONSISTENCY )\nWe introduce a new \u2018deep memory retrieval\u2019 (DMR) task based on the MSC dataset designed to test\nthe consistency of a conversational agent In DMR, the conversational agent is asked a question by\nthe user that explicitly refers back to a prior conversation and has a very narrow expected answer\nrange (see Figure 5 for an example) We generated the DMR question-answer (QA) pairs using\na separate LLM that was instructed to write a question from one user to another that could only\nbe answered correctly using knowledge gained from the past sessions (see Appendix for further\ndetails) We evaluate the quality of the generated response against the \u2018gold response\u2019 using ROUGE-L scores\n(Lin, 2004) and an \u2018LLM judge\u2019, which is instructed to evaluate whether or not the generated re-\nsponse is consistent with the gold response (GPT-4 has been shown to have high agreement with\nhuman evaluators (Zheng et al., 2023)) In practice, we notice that the generated responses (from\nboth MemGPT and the baselines) were generally more verbose than the gold responses; ROUGE-\nL (which measures the longest common subsequence between the generated and reference text) is\nrobust to this semantic variation in correct responses since it evaluates the presence of words from\nthe gold answer in the generated answer We also report the precision and recall scores used in\ncalclating the ROUGE-L (F1) score MemGPT utilizes memory to maintain coherence: Table 2 shows the performance of MemGPT\nvs the fixed-memory baselines We compare against three variations of fixed-context baselines: an\nagent that see a recursive summary of the past five conversations (summary 1:5), an agent that can\n7Preprint\nTable 2: Deep memory retrieval (DMR) performance In this task, the agent is asked a spe-\ncific question about a topic discussed in a prior conversation (sessions 1\u20135) The agent\u2019s response\nis scored against the gold answer Methods using the gold persona (oracle) are marked with \u2021 MemGPT significantly outperforms the (non-oracle) fixed-context baselines", "summary": "SPR:\n- MemGPT, a conversational agent, aims to satisfy two key criteria: consistency and engagement.\n- Consistency is achieved by aligning new facts, preferences, and events with prior statements from both the user and the agent.\n- Engagement is enhanced by leveraging long-term knowledge about the user to personalize responses and referencing prior conversations.\n- MemGPT is evaluated on its ability to maintain conversation consistency and produce engaging dialogue compared to fixed-context baselines.\n- Deep memory retrieval (DMR) is introduced as a task to test the consistency of a conversational agent.\n- MemGPT utilizes memory to improve conversation consistency and outperforms fixed-context baselines in the DMR task.", "clean_entities": [], "dirty_entities": ["Entities: MemGPT", "Taylor Swift", "Multi-Session Chat (MSC)", "Xu et al.", "DMR", "LLM", "ROUGE-L", "GPT-4", "Zheng et al.", "", "Keywords: consistency", "engagement", "memory", "coherence", "facts", "preferences", "events", "dialogue", "long-term knowledge", "natural", "personalize", "conversation", "fixed-context", "benefits", "conversational agents", "recall memory", "artist", "music", "deep memory retrieval", "dataset", "sessions", "persona", "question-answer", "answer range", "quality", "gold response", "ROUGE-L scores", "LLM judge", "performance", "variations", "fixed-memory baselines", "recursive summary", "precision", "recall", "F1 score", "topic", "prior conversation", "oracle", "", "Key Phrases: long-term conversational interaction", "unbounded context", "meaningful benefits", "prior conversations", "personalized responses", "consistent persona", "deep memory retrieval task", "generated response", "semantic variation", "coherence maintenance", "fixed-context baselines", "DMR performance", "specific question", "gold persona", "non-oracle", "significantly outperforms", "", "References: Taylor Swift", "Multi-Session Chat (MSC)", "Xu et al. (2021)", "ROUGE-L (Lin", "2004)", "GPT-4 (Zheng et al.", "2023)"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "MemGPT - Justification: MemGPT is the main subject of the summary, as it is a conversational agent that aims to achieve consistency and engagement.", "justification": ""}, {"topic": "Criteria for Conversational Agents - Justification: The summary mentions that MemGPT aims to satisfy two key criteria: consistency and engagement. This topic explores the criteria that are important for conversational agents.", "justification": ""}, {"topic": "Consistency in Conversations - Justification: The summary highlights that consistency is achieved by aligning new facts, preferences, and events with prior statements. This topic focuses on the importance of maintaining consistency in conversations.", "justification": ""}, {"topic": "Engagement in Conversations - Justification: The summary mentions that engagement is enhanced by leveraging long-term knowledge about the user and referencing prior conversations. This topic explores strategies to improve engagement in conversations.", "justification": ""}, {"topic": "Evaluation of MemGPT - Justification: The summary states that MemGPT is evaluated on its ability to maintain conversation consistency and produce engaging dialogue compared to fixed-context baselines. This topic discusses the evaluation process of MemGPT.", "justification": ""}, {"topic": "Deep Memory Retrieval (DMR) - Justification: The summary introduces DMR as a task to test the consistency of a conversational agent. This topic explores the concept of DMR and its relevance in evaluating conversational agents.", "justification": ""}, {"topic": "Memory Utilization in MemGPT - Justification: The summary mentions that MemGPT utilizes memory to improve conversation consistency and outperforms fixed-context baselines in the DMR task. This topic focuses on how MemGPT uses memory to enhance its performance.", "justification": ""}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does MemGPT aim to achieve consistency and engagement in conversations?"}, {"question_type": "Analytical Question", "question": "What are the key criteria for evaluating MemGPT's performance in maintaining conversation consistency and producing engaging dialogue?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine you are using MemGPT as a conversational agent. How would it leverage your long-term knowledge to personalize responses and reference prior conversations?"}, {"question_type": "Contextual/Relational Question", "question": "How does MemGPT's utilization of memory improve conversation consistency compared to fixed-context baselines?"}, {"question_type": "User-Interactive Question", "question": "In what ways do you think MemGPT's ability to align new facts, preferences, and events with prior statements from both the user and the agent can enhance user engagement in conversations?"}], "knowledge_triplets": [{"subject": "MemGPT", "relationship": "leverage", "target": "memory"}, {"subject": "MemGPT", "relationship": "improve", "target": "conversation consistency"}, {"subject": "MemGPT", "relationship": "remember", "target": "relevant facts, preferences, and events"}, {"subject": "MemGPT", "relationship": "maintain", "target": "coherence"}, {"subject": "MemGPT", "relationship": "produce", "target": "engaging dialogue"}, {"subject": "MemGPT", "relationship": "incorporate", "target": "long-range user information"}, {"subject": "MemGPT", "relationship": "personalize", "target": "messages"}, {"subject": "MemGPT", "relationship": "handle", "target": "challenges of long-term conversational interaction"}, {"subject": "MemGPT", "relationship": "provide", "target": "meaningful benefits for conversational agents"}, {"subject": "Taylor Swift", "relationship": "mentioned", "target": "artist"}, {"subject": "MemGPT", "relationship": "utilizes memory to maintain coherence", "target": "Table 2"}, {"subject": "Taylor Swift", "relationship": "mentioned in past conversation about music", "target": "User"}, {"subject": "Multi-Session Chat (MSC)", "relationship": "dataset used for evaluation", "target": "3.1.1 D ATASET"}, {"subject": "Xu et al.", "relationship": "authors of the MSC dataset", "target": "3.1.1 D ATASET"}, {"subject": "DMR", "relationship": "task introduced to test conversational agent consistency", "target": "3.1.2 D EEP MEMORY RETRIEVAL TASK (CONSISTENCY"}, {"subject": "LLM", "relationship": "separate language model used to generate DMR question-answer pairs", "target": "3.1.2 D EEP MEMORY RETRIEVAL TASK (CONSISTENCY"}, {"subject": "ROUGE-L", "relationship": "evaluation metric used to compare generated responses", "target": "3.1.2 D EEP MEMORY RETRIEVAL TASK (CONSISTENCY"}, {"subject": "GPT-4", "relationship": "conversational agent with high agreement with human evaluators", "target": "3.1.2 D EEP MEMORY RETRIEVAL TASK (CONSISTENCY"}, {"subject": "Zheng et al.", "relationship": "authors who showed GPT-4's high agreement with human evaluators", "target": "3.1.2 D EEP MEMORY RETRIEVAL TASK (CONSISTENCY"}, {"subject": "fixed-context baselines", "relationship": "compared against MemGPT in DMR performance", "target": "Table 2"}, {"subject": "MemGPT", "relationship": "leverage", "target": "memory"}, {"subject": "MemGPT", "relationship": "improve", "target": "conversation consistency"}, {"subject": "MemGPT", "relationship": "remember", "target": "relevant facts, preferences, and events"}, {"subject": "MemGPT", "relationship": "maintain", "target": "coherence"}, {"subject": "MemGPT", "relationship": "produce", "target": "engaging dialogue"}, {"subject": "MemGPT", "relationship": "incorporate", "target": "long-range user information"}, {"subject": "MemGPT", "relationship": "personalize", "target": "messages"}, {"subject": "MemGPT", "relationship": "handle", "target": "challenges of long-term conversational interaction"}, {"subject": "MemGPT", "relationship": "provide", "target": "meaningful benefits for conversational agents"}, {"subject": "Taylor Swift", "relationship": "mentioned", "target": "artist"}], "timestamp": "2024-01-14T17:29:35.118968"}, {"file_id": "2310.08560", "article": "Chunk # 5.\nROUGE-L\nModel Available information Accuracy \u21d1F1\u21d1 P\u21d1 R\u21d1\ngpt-3.5\u2021persona 5+ summary 1:5 70.0% 0.190 0.134 0.674\ngpt-4\u2021persona 5+ summary 1:5 79.8% 0.225 0.151 0.716\nMemGPT\u2021persona 5(Core) + dialogue 1:5(Recall) 84.0% 0.171 0.105 0.746\ngpt-3.5 summary 1:5 56.2% 0.157 0.114 0.585\ngpt-3.5 summary 1:4+ dialogue 5 55.6% 0.120 0.080 0.602\ngpt-4 summary 1:5 63.0% 0.159 0.101 0.607\ngpt-4 summary 1:4+ dialogue 5 79.2% 0.171 0.107 0.713\nMemGPT dialogue 1:5(Recall) 82.4% 0.173 0.106 0.743\nsee a recursive summary of the first four conversations (summary 1:4) and the exact contents of the\nprior conversation (dialogue 5is placed in active memory), as well as an oracle agent that can see the\ngold persona (for both chat participants) as well as a recursive summary We experiment with these\ncontext variations using both GPT-3.5 and GPT-4 All of the gold persona baselines perform near-perfectly: this is because the human-labelled gold\npersonas in the MSC dataset are detailed and intended to be a concise summary of all stated persona\ninformation in all prior chats - in other words, a well-written gold persona should contain the answer\nto the DMR question Among the non-oracle fixed-context baselines, GPT-4 significantly outper-\nforms GPT-3.5, and with both models the variations that had access to the full prior conversation\nin active memory perform slightly better The drop in performance from summary 1:4+ dialogue 5\nto summary 1:5is expected, since the latter should contain strictly less information than the former\n(assuming a perfect summarizer with restricted length summarizations) MemGPT significantly\noutperforms both GPT-4 and GPT-3.5 in both LLM judge accuracy and ROUGE-L scores: instead\nof relying on recursive summaries to extend context, MemGPT is able to query past conversation\nhistory in its Recall Memory to answer the DMR questions 3.1.3 C ONVERSATION OPENER TASK (ENGAGEMENT )\nIn the \u2018conversation opener\u2019 task we evaluate an agent\u2019s ability to craft engaging messages to the user\nthat draw from knowledge accumulated in prior conversations To evaluate the \u2018engagingness\u2019 of a\nconversation opener using the MSC dataset, we compare the generated opener to the gold personas:\nan engaging conversation opener should draw from one (or several) of the data points contained\nin the persona, which in MSC effectively summarize the knowledge accumulated throughout all\nprior sessions (see Figure 6 for an example) We also compare to the human-generated gold opener,\ni.e., the first response in the following session Because the quality of conversation openers is not\nnecessarily constrained by context length (a recursive summary or even a few snippets from prior\nconversations is enough to craft an opener that uses prior knowledge), we use this task to ablate\nMemGPT\u2019s different components (rather than compare it to fixed-context baselines) We report the CSIM scores of MemGPT\u2019s openers in Table 3 We test several variations of\nMemGPT: MemGPT without working context (storing persona information) and recall storage (stor-\ning conversation information), MemGPT without working context or without recall storage, and\nMemGPT with both working context and recall storage enabled MemGPT utilizes memory to increase engagement: As seen in Table 3 and Figure 6, MemGPT\nis able to craft engaging openers that perform similarly to and occasionally exceed the hand-written\nhuman openers We observe that MemGPT tends to craft openers that are both more verbose and\ncover more aspects of the persona information than the human baseline Additionally, we can see\nthe storing information in working context is key to generating engaging openers Without working\ncontext, MemGPT \u2019s openers significantly degrade in quality; having the dialogue stored in recall\n8Preprint\nTable 3: Conversation opener performance (session 5) The agent\u2019s conversation opener is\nevaluated using similarity scores to the gold persona labels CSIM-1 scores the closest persona\nfragment match to the opener and CSIM-3 scores is the average of the top 3 matches Method CSIM-1 \u21d1CSIM-3 \u21d1CSIM-H \u21d1\nGold opener (human baseline) 0.823 0.787 1.000\nMemGPT (working context + recall storage) 0.817 0.787 0.760\nMemGPT (working context only) 0.820 0.790 0.762\nMemGPT (recall storage only) 0.749 0.738 0.737\nI am studying the LSAT  I want to be an attorney I used to live in New Mexico in a small\ntown I grew up with horses I love coffee  I love tea ...Gold persona (user)\nWhat date is your LSAT test scheduled?Gold opener (human baseline)\nHello there Just brewing up a fresh pot of teaon my end How\u2019s your coffee  Ready to\nburn the midnight oil with some LSAT study ?MemGPT (working context + recall storage) \u2713\nHello It\u2019s great to have you back It\u2019s time for a fresh cup of coffee  As a tour guide at\nour local museum, I meet so many people who say a good brew helps keep them focused How\u2019s your LSAT study going?MemGPT (working context only) \u2713\nHey there It\u2019s always a pleasure to see you online", "summary": "SPR:\n\n1. GPT-4 outperforms GPT-3.5 in accuracy and ROUGE-L scores.\n2. MemGPT performs better than GPT-4 and GPT-3.5 by utilizing recall memory.\n3. MemGPT generates engaging conversation openers using accumulated knowledge.\n4. Working context and recall storage are crucial for MemGPT's performance.\n5. MemGPT's openers are more verbose and cover more aspects than human baselines.", "clean_entities": [], "dirty_entities": ["Entities: gpt-3.5", "gpt-4", "MemGPT", "ROUGE-L", "AI", "MSC dataset", "DMR question", "LLM judge", "CSIM", "LSAT test", "", "Keywords: summary", "dialogue", "conversation opener", "engagement", "gold persona", "baseline", "context", "recall storage", "working context", "opener performance", "", "Key Phrases: recursive summary", "prior conversation", "gold persona baselines", "fixed-context baselines", "conversation opener task", "conversation openers", "human-generated gold opener", "working context", "recall storage", "engaging openers", "LSAT test scheduled", "", "References: gpt-3.5 summary 1:5", "gpt-3.5 summary 1:4+ dialogue 5", "gpt-4 summary 1:5", "gpt-4 summary 1:4+ dialogue 5", "MemGPT dialogue 1:5(Recall)", "gold personas", "MSC dataset", "CSIM-1", "CSIM-3", "CSIM-H", "", "Abstract Concepts: accuracy", "F1 score", "precision", "recall", "context length", "engagement", "knowledge accumulation", "opener quality", "verbosity", "persona information", "dialogue storage"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "GPT-4 vs GPT-3.5 performance comparison", "justification": "The first two statements compare the performance of GPT-4 and GPT-3.5, highlighting the superiority of GPT-4 in terms of accuracy and ROUGE-L scores."}, {"topic": "MemGPT vs GPT-4 and GPT-3.5 performance comparison", "justification": "The second statement compares the performance of MemGPT with GPT-4 and GPT-3.5, showcasing the advantage of MemGPT by utilizing recall memory."}, {"topic": "MemGPT's ability to generate engaging conversation openers", "justification": "The third statement emphasizes MemGPT's capability to generate engaging conversation openers using accumulated knowledge."}, {"topic": "Importance of working context and recall storage for MemGPT's performance", "justification": "The fourth statement highlights the significance of working context and recall storage for MemGPT's performance."}, {"topic": "Comparison of MemGPT's openers with human baselines", "justification": "The fifth statement compares MemGPT's conversation openers with human baselines, highlighting the verbosity and coverage of MemGPT's openers."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does GPT-4 compare to GPT-3.5 in terms of accuracy and ROUGE-L scores?"}, {"question_type": "Analytical Question", "question": "What are the key factors that contribute to MemGPT outperforming GPT-4 and GPT-3.5?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a conversation between MemGPT and a human. How would MemGPT's conversation openers, based on accumulated knowledge, differ from those of a human?"}, {"question_type": "Contextual/Relational Question", "question": "How does the performance of MemGPT depend on the working context and recall storage?"}, {"question_type": "User-Interactive Question", "question": "In what ways can MemGPT's more verbose and comprehensive conversation openers enhance user engagement compared to human baselines?"}], "knowledge_triplets": [{"subject": "ROUGE-L", "relationship": "is a model of", "target": "gpt-3.5"}, {"subject": "ROUGE-L", "relationship": "is a model of", "target": "gpt-4"}, {"subject": "ROUGE-L", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "gpt-3.5", "relationship": "has accuracy of", "target": "70.0%"}, {"subject": "gpt-3.5", "relationship": "has F1 score of", "target": "0.190"}, {"subject": "gpt-3.5", "relationship": "has P score of", "target": "0.134"}, {"subject": "gpt-3.5", "relationship": "has R score of", "target": "0.674"}, {"subject": "gpt-4", "relationship": "has accuracy of", "target": "79.8%"}, {"subject": "gpt-4", "relationship": "has F1 score of", "target": "0.225"}, {"subject": "gpt-4", "relationship": "has P score of", "target": "0.151"}, {"subject": "gpt-4", "relationship": "has R score of", "target": "0.716"}, {"subject": "MemGPT", "relationship": "has accuracy of", "target": "84.0%"}, {"subject": "MemGPT", "relationship": "has F1 score of", "target": "0.171"}, {"subject": "MemGPT", "relationship": "has P score of", "target": "0.105"}, {"subject": "MemGPT", "relationship": "has R score of", "target": "0.746"}, {"subject": "gpt-3.5", "relationship": "has accuracy of", "target": "56.2%"}, {"subject": "gpt-3.5", "relationship": "has F1 score of", "target": "0.157"}, {"subject": "gpt-3.5", "relationship": "has P score of", "target": "0.114"}, {"subject": "gpt-3.5", "relationship": "has R score of", "target": "0.585"}, {"subject": "gpt-3.5", "relationship": "has accuracy of", "target": "55.6%"}, {"subject": "gpt-3.5", "relationship": "has F1 score of", "target": "0.120"}, {"subject": "gpt-3.5", "relationship": "has P score of", "target": "0.080"}, {"subject": "gpt-3.5", "relationship": "has R score of", "target": "0.602"}, {"subject": "gpt-4", "relationship": "has accuracy of", "target": "63.0%"}, {"subject": "gpt-4", "relationship": "has F1 score of", "target": "0.159"}, {"subject": "gpt-4", "relationship": "has P score of", "target": "0.101"}, {"subject": "gpt-4", "relationship": "has R score of", "target": "0.607"}, {"subject": "gpt-4", "relationship": "has accuracy of", "target": "79.2%"}, {"subject": "gpt-4", "relationship": "has F1 score of", "target": "0.171"}, {"subject": "gpt-4", "relationship": "has P score of", "target": "0.107"}, {"subject": "gpt-4", "relationship": "has R score of", "target": "0.713"}, {"subject": "MemGPT", "relationship": "has accuracy of", "target": "82.4%"}, {"subject": "MemGPT", "relationship": "has F1 score of", "target": "0.173"}, {"subject": "MemGPT", "relationship": "has P score of", "target": "0.106"}, {"subject": "MemGPT", "relationship": "has R score of", "target": "0.743"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "gpt-3.5"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "gpt-4"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-3.5", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "GPT-4", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "gpt-3.5", "relationship": "performs", "target": "significantly outper-forms"}, {"subject": "gpt-4", "relationship": "significantly outper-forms", "target": "GPT-3.5"}, {"subject": "GPT-4", "relationship": "outper-forms", "target": "GPT-3.5"}, {"subject": "MemGPT", "relationship": "significantly outper-forms", "target": "GPT-4 and GPT-3.5"}, {"subject": "MemGPT", "relationship": "utilizes", "target": "memory to increase engagement"}, {"subject": "MemGPT", "relationship": "tends to craft", "target": "openers that are both more verbose and cover more aspects of the persona information than the human baseline"}, {"subject": "working context", "relationship": "is key to generating", "target": "engaging openers"}, {"subject": "working context", "relationship": "significantly degrade", "target": "in quality without dialogue stored in recall"}, {"subject": "recall storage", "relationship": "significantly degrade", "target": "in quality without working context"}, {"subject": "MemGPT (working context + recall storage)", "relationship": "able to craft", "target": "engaging openers that perform similarly to and occasionally exceed the hand-written human openers"}, {"subject": "MemGPT (working context + recall storage)", "relationship": "tends to craft", "target": "openers that are both more verbose and cover more aspects of the persona information than the human baseline"}, {"subject": "ROUGE-L", "relationship": "is a model of", "target": "gpt-3.5"}, {"subject": "ROUGE-L", "relationship": "is a model of", "target": "gpt-4"}, {"subject": "ROUGE-L", "relationship": "is a model of", "target": "MemGPT"}, {"subject": "gpt-3.5", "relationship": "has accuracy of", "target": "70.0%"}, {"subject": "gpt-3.5", "relationship": "has F1 score of", "target": "0.190"}, {"subject": "gpt-3.5", "relationship": "has P score of", "target": "0.134"}, {"subject": "gpt-3.5", "relationship": "has R score of", "target": "0.674"}, {"subject": "gpt-4", "relationship": "has accuracy of", "target": "79.8%"}, {"subject": "gpt-4", "relationship": "has F1 score of", "target": "0.225"}, {"subject": "gpt-4", "relationship": "has P score of", "target": "0.151"}, {"subject": "gpt-4", "relationship": "has R score of", "target": "0.716"}, {"subject": "MemGPT", "relationship": "has accuracy of", "target": "84.0%"}, {"subject": "MemGPT", "relationship": "has F1 score of", "target": "0.171"}, {"subject": "MemGPT", "relationship": "has P score of", "target": "0.105"}, {"subject": "MemGPT", "relationship": "has R score of", "target": "0.746"}, {"subject": "gpt-3.5", "relationship": "has accuracy of", "target": "56.2%"}, {"subject": "gpt-3.5", "relationship": "has F1 score of", "target": "0.157"}, {"subject": "gpt-3.5", "relationship": "has P score of", "target": "0.114"}, {"subject": "gpt-3.5", "relationship": "has R score of", "target": "0.585"}, {"subject": "gpt-3.5", "relationship": "has accuracy of", "target": "55.6%"}, {"subject": "gpt-3.5", "relationship": "has F1 score of", "target": "0.120"}, {"subject": "gpt-3.5", "relationship": "has P score of", "target": "0.080"}, {"subject": "gpt-3.5", "relationship": "has R score of", "target": "0.602"}, {"subject": "gpt-4", "relationship": "has accuracy of", "target": "63.0%"}], "timestamp": "2024-01-14T17:30:27.896404"}, {"file_id": "2310.08560", "article": "Chunk # 6.\nLet\u2019s dive into the world of shared ideas,\nshall we?MemGPT (recall storage only) \u2717\nFigure 6: An engaging conversation opener should draw from the provided persona information Without working context, MemGPT\u2019s openers significantly degrade in quality Having the dialogue\nstored in recall memory does not affect the opener, since MemGPT will generally not attempt to\nsearch the conversation history before generating an opener storage does not affect the opener, since MemGPT will generally not attempt to search the conver-\nsation history before generating an opener 3.2 M EMGPT FOR DOCUMENT ANALYSIS\nDocument analysis also faces challenges due to the limited context windows of today\u2019s transformer\nmodels For example, OpenAI\u2019s (closed) GPT models behind their popular ChatGPT consumer\nchatbot application have a limit of 32k input tokens, and the state-of-the-art open source Llama 2\nmodels have a limit of only 4k tokens (see Table 1) Anthropic have released (closed) models han-\ndling up to 100k tokens, but many documents easily surpass that length; Stephen King\u2019s bestselling\nnovel The Shining contains around 150k words, which equates to roughly 200k tokens (words-to-\ntoken varies based on the specific tokenizer used), and legal or financial documents such as Annual\nReports (SEC Form 10-K) can easily pass the million token mark Moreover, many real document\nanalysis tasks require drawing connections across multiple such lengthy documents Anticipating\nthese scenarios, it becomes difficult to envision blindly scaling up context as a solution to the fixed-\ncontext problem Recent research (Liu et al., 2023a) also raises doubts about the utility of simply\nscaling contexts, since they find uneven attention distributions in large context models (the model is\nmore capable of recalling information at the beginning or end of its context window, vs tokens in the\nmiddle) To enable reasoning across documents, more flexible memory architectures such as those\nused in MemGPT are likely needed 9Preprint\n 0 0.2 0.4 0.6 0.8 1\n 0 100  200  300  400  500  600  700Accuracy\nDocuments retrievedGPT-3.5\nGPT-4\nMemGPT\n 0 0.2 0.4 0.6 0.8 1\n 0  1  2  3  4Accuracy\nNesting levelsGPT-3.5\nGPT-4\nMemGPT\nFigure 7: Document QA and nested KV retrieval task performance In both tasks, MemGPT\u2019s\nperformance is unaffected by increased context length Methods such as truncation can extend the\neffective context lengths (past the dotted red line ) of fixed length models such as GPT-4, but such\ncompression methods will lead to performance degredation as the necessary compression grows\n(compression is particularly bad for key-value retrieval tasks, since it corrupts the key-value pairs) 3.2.1 M ULTI -DOCUMENT QUESTION -ANSWERING (DOC-QA)\nTo evaluate MemGPT\u2019s ability to analyze documents, we benchmark MemGPT against fixed-context\nbaselines on the retriever-reader document QA task from Liu et al (2023a) In this task, a question\nis selected from the NaturalQuestions-Open dataset, and a retriever selects relevant Wikipedia doc-\numents for the question A reader model (the LLM) is then fed these documents as input, and is\nasked to use the provided documents to answer the question Similar to Liu et al (2023a), we evalu-\nate reader accuracy as the number of retrieved documents Kincreases In our evaluation setup, both\nthe fixed-context baselines and MemGPT use the same retriever, which selects the top Kdocuments\naccording using Faiss efficient similarity search (Johnson et al., 2019) (which corresponds to ap-\nproximate nearest neighbor search) on OpenAI\u2019s text-embedding-ada-002 embeddings In\nMemGPT, the entire document set is loaded into archival storage, and the retriever naturally emerges\nvia the archival storage search functionality (which performs embedding-based similarity search) In the fixed-context baselines, the top- Kdocuments are fetched using the retriever independently\nfrom the LLM inference, similar to the original retriever-reader setup We use a dump of Wikipedia\nfrom late 2018, following past work on NaturalQuestions-Open (Izacard & Grave, 2020; Izacard\net al., 2021) We randomly sample a subset of 50 questions for each point in the graph The fixed-context baselines performance is capped roughly at the performance of the retriever, as\nthey use the information that is presented in their context window (e.g if the embedding search\nretriever fails to surface the gold article using the provided question, the fixed-context baselines are\nguaranteed to never see the gold article) By contrast, MemGPT is effectively able to make multiple\ncalls to the retriever by querying archival storage, allowing it to scale to larger effective context\nlengths MemGPT actively retrieves documents from its archival storage (and can iteratively page\nthrough results), so the total number of documents available to MemGPT is no longer limited by the\nnumber of documents that fit within the LLM processor\u2019s context window The document QA task is challenging for all methods due to the limitations of embedding-based\nsimilarity search We observe that the golden document for chosen question (as annotated by\nNaturalQuestions-Open) often appears outside of the first dozen retrieved results, if not even fur-\nther", "summary": "Revised Summary: MemGPT, a model for document analysis, overcomes the limitations of limited context windows in transformer models like GPT. GPT models, such as the one behind ChatGPT, have a token limit of 32k, which is insufficient for lengthy documents like Stephen King's novel The Shining or legal/financial documents with millions of tokens. To handle longer documents, more flexible memory architectures like MemGPT are needed. In the retriever-reader document QA task, MemGPT outperforms fixed-context baselines by utilizing archival storage for document retrieval. Reader accuracy is evaluated based on the number of retrieved documents. Unlike fixed-context baselines, MemGPT actively retrieves documents from its archival storage, allowing it to scale to larger effective context lengths. However, embedding-based similarity search poses challenges for all methods, as the golden document for a chosen question may not appear in the first dozen retrieved results.", "clean_entities": ["\"Without working context", "\"limited context windows of today\u2019s transformer models\"", "\"GPT models behind their popular ChatGPT consumer chatbot application\"", "\"limit of 32k input tokens\"", "\"limit of only 4k tokens\"", "\"many documents easily surpass that length\"", "\"Stephen King\u2019s bestselling novel The Shining contains around 150k words\"", "\"legal or financial documents such as Annual Reports (SEC Form 10-K) can easily pass the million token mark\"", "\"more flexible memory architectures such as those used in MemGPT are likely needed\"", "\"benchmark MemGPT against fixed-context baselines on the retriever-reader document QA task\"", "\"a question is selected from the NaturalQuestions-Open dataset\"", "\"retriever selects relevant Wikipedia documents for the question\"", "\"reader model (the LLM) is then fed these documents as input\"", "\"evaluate reader accuracy as the number of retrieved documents increases\"", "\"fixed-context baselines and MemGPT use the same retriever\"", "\"the top-K documents are fetched using the retriever independently from the LLM inference\"", "\"use a dump of Wikipedia from late 2018\"", "\"fixed-context baselines performance is capped roughly at the performance of the retriever\"", "\"MemGPT actively retrieves documents from its archival storage\"", "\"the total number of documents available to MemGPT is no longer limited by the number of documents that fit within the LLM processor\u2019s context window\"", "\"challenging for all methods due to the limitations of embedding-based similarity search\"", "\"golden document for chosen question often appears outside of the first dozen retrieved results\""], "dirty_entities": ["Entities: MemGPT", "GPT models", "ChatGPT", "Llama 2", "Anthropic", "Stephen King", "The Shining", "Annual Reports (SEC Form 10-K)", "Liu et al.", "MemGPT", "GPT-3.5", "GPT-4", "MemGPT", "NaturalQuestions-Open dataset", "LLM", "Faiss", "Johnson et al.", "Izacard & Grave", "Izacard et al.", "Wikipedia", "", "Keywords: shared ideas", "conversation opener", "recall memory", "document analysis", "limited context windows", "transformer models", "input tokens", "state-of-the-art", "open source", "Llama 2", "tokens", "novel", "The Shining", "words-to-token", "legal", "financial documents", "Annual Reports", "SEC Form 10-K", "million token mark", "document analysis tasks", "connections", "lengthy documents", "scaling up context", "fixed-context problem", "recent research", "attention distributions", "flexible memory architectures", "reasoning across documents", "document QA", "nested KV retrieval task", "performance", "truncation", "compression methods", "key-value retrieval tasks", "multi-document question-answering", "benchmark", "fixed-context baselines", "retriever-reader document QA task", "NaturalQuestions-Open dataset", "Wikipedia documents", "reader model", "reader accuracy", "retrieved documents", "Faiss efficient similarity search", "embeddings", "archival storage", "retriever-reader setup", "dump of Wikipedia", "effective context lengths", "golden document", "embedding-based similarity search", "", "Phrases:", "MemGPT\u2019s openers significantly degrade in quality\""], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "MemGPT and its advantages over limited context window models", "justification": "MemGPT overcomes the limitations of limited context windows in transformer models like GPT, which have a token limit of 32k."}, {"topic": "Challenges with limited context windows in transformer models", "justification": "Limited context windows in transformer models like GPT pose limitations for lengthy documents and documents with millions of tokens."}, {"topic": "Need for more flexible memory architectures for handling longer documents", "justification": "Longer documents like Stephen King's novel The Shining or legal/financial documents with millions of tokens require more flexible memory architectures like MemGPT."}, {"topic": "MemGPT's performance in the retriever-reader document QA task", "justification": "MemGPT outperforms fixed-context baselines in the retriever-reader document QA task by utilizing archival storage for document retrieval."}, {"topic": "Evaluation of reader accuracy in the retriever-reader document QA task", "justification": "Reader accuracy in the retriever-reader document QA task is evaluated based on the number of retrieved documents."}, {"topic": "Challenges with embedding-based similarity search in document retrieval", "justification": "Embedding-based similarity search poses challenges for all methods as the golden document for a chosen question may not appear in the first dozen retrieved results."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does MemGPT address the limitations of limited context windows in transformer models like GPT?"}, {"question_type": "Analytical Question", "question": "What is the token limit for GPT models like the one behind ChatGPT, and why is it insufficient for lengthy documents?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine you are working with a legal document that has millions of tokens. How can MemGPT's flexible memory architecture be beneficial in this scenario?"}, {"question_type": "Contextual/Relational Question", "question": "How does MemGPT outperform fixed-context baselines in the retriever-reader document QA task?"}, {"question_type": "User-Interactive Question", "question": "As a user, how would you feel about MemGPT actively retrieving documents from its archival storage instead of relying on fixed-context baselines? How might this impact your experience with the model?"}], "knowledge_triplets": [{"subject": "MemGPT", "relationship": "is used in", "target": "document analysis"}, {"subject": "GPT models", "relationship": "are behind", "target": "ChatGPT consumer chatbot application"}, {"subject": "ChatGPT consumer chatbot application", "relationship": "has a limit of", "target": "32k input tokens"}, {"subject": "Llama 2 models", "relationship": "have a limit of", "target": "4k tokens"}, {"subject": "documents", "relationship": "can easily surpass", "target": "that length"}, {"subject": "Stephen King\u2019s bestselling novel The Shining", "relationship": "contains around", "target": "150k words"}, {"subject": "Annual Reports (SEC Form 10-K)", "relationship": "can easily pass", "target": "the million token mark"}, {"subject": "more flexible memory architectures", "relationship": "are likely needed", "target": "in MemGPT"}, {"subject": "MemGPT", "relationship": "is benchmarked against", "target": "fixed-context baselines"}, {"subject": "retriever", "relationship": "selects", "target": "relevant Wikipedia documents"}, {"subject": "reader model (the LLM)", "relationship": "is fed", "target": "documents as input"}, {"subject": "reader accuracy", "relationship": "increases as", "target": "the number of retrieved documents increases"}, {"subject": "fixed-context baselines and MemGPT", "relationship": "use the same", "target": "retriever"}, {"subject": "top-K documents", "relationship": "are fetched using", "target": "the retriever independently from the LLM inference"}, {"subject": "Wikipedia", "relationship": "is used as the dataset for", "target": "the document QA task"}, {"subject": "fixed-context baselines performance", "relationship": "is capped roughly at", "target": "the performance of the retriever"}, {"subject": "MemGPT", "relationship": "actively retrieves", "target": "documents from its archival storage"}, {"subject": "the total number of documents available to MemGPT", "relationship": "is no longer limited by", "target": "the number of documents that fit within the LLM processor\u2019s context window"}, {"subject": "embedding-based similarity search", "relationship": "is challenging for", "target": "all methods"}, {"subject": "golden document for chosen question", "relationship": "often appears outside of", "target": "the first dozen retrieved results"}, {"subject": "MemGPT", "relationship": "is used for", "target": "document analysis"}, {"subject": "GPT models", "relationship": "are used behind", "target": "ChatGPT consumer chatbot application"}, {"subject": "Llama 2 models", "relationship": "have a limit of", "target": "4k tokens"}, {"subject": "Stephen King\u2019s bestselling novel The Shining", "relationship": "contains", "target": "around 150k words"}, {"subject": "Annual Reports (SEC Form 10-K)", "relationship": "can easily pass", "target": "the million token mark"}, {"subject": "Liu et al.", "relationship": "raise doubts about", "target": "scaling contexts"}, {"subject": "MemGPT", "relationship": "uses", "target": "flexible memory architectures"}, {"subject": "MemGPT", "relationship": "is unaffected by", "target": "increased context length"}, {"subject": "MemGPT", "relationship": "is benchmarked against", "target": "fixed-context baselines"}, {"subject": "MemGPT", "relationship": "uses the same retriever as", "target": "fixed-context baselines"}, {"subject": "Faiss efficient similarity search", "relationship": "is used for", "target": "selecting top K documents"}, {"subject": "MemGPT", "relationship": "loads the entire document set into", "target": "archival storage"}, {"subject": "MemGPT", "relationship": "can make multiple calls to", "target": "the retriever"}, {"subject": "MemGPT", "relationship": "actively retrieves documents from", "target": "archival storage"}, {"subject": "MemGPT", "relationship": "scales to", "target": "larger effective context lengths"}, {"subject": "Document QA task", "relationship": "is challenging for", "target": "all methods"}, {"subject": "Golden document", "relationship": "often appears outside of", "target": "the first dozen retrieved results"}, {"subject": "MemGPT", "relationship": "is used for", "target": "document analysis"}, {"subject": "GPT models", "relationship": "are used behind", "target": "ChatGPT consumer chatbot application"}, {"subject": "Llama 2 models", "relationship": "have a limit of", "target": "4k tokens"}, {"subject": "Stephen King\u2019s bestselling novel The Shining", "relationship": "contains", "target": "around 150k words"}, {"subject": "Annual Reports (SEC Form 10-K)", "relationship": "can easily pass", "target": "the million token mark"}, {"subject": "Liu et al.", "relationship": "raise doubts about", "target": "scaling contexts"}, {"subject": "MemGPT", "relationship": "uses", "target": "flexible memory architectures"}, {"subject": "MemGPT", "relationship": "is unaffected by", "target": "increased context length"}, {"subject": "MemGPT", "relationship": "is benchmarked against", "target": "fixed-context baselines"}, {"subject": "MemGPT", "relationship": "uses the same retriever as", "target": "fixed-context baselines"}, {"subject": "Faiss efficient similarity search", "relationship": "is used for", "target": "selecting top K documents"}, {"subject": "MemGPT", "relationship": "loads the entire document set into", "target": "archival storage"}, {"subject": "MemGPT", "relationship": "can make multiple calls to", "target": "the retriever"}, {"subject": "MemGPT", "relationship": "actively retrieves documents from", "target": "archival storage"}, {"subject": "MemGPT", "relationship": "scales to", "target": "larger effective context lengths"}, {"subject": "Document QA task", "relationship": "is challenging for", "target": "all methods"}, {"subject": "Golden document", "relationship": "often appears outside of", "target": "the first dozen retrieved results"}], "timestamp": "2024-01-14T17:31:28.958922"}, {"file_id": "2310.08560", "article": "Chunk # 7.\nThe retriever performance translates directly to the fixed-context baseline results: GPT-3.5 and\nGPT-4\u2019s accuracy is relatively low with few retrieved documents, and continues to improve as addi-\ntional documents are added to the context window While MemGPT is theoretically not limited by\nsub-optimal retriever performance (even if the embedding-based ranking is noisy, as long as the full\nretriever ranking contains the gold document it can still be found with enough retriever calls via pag-\nination), we observe that MemGPT will often stop paging through retriever results before exhausting\nthe retriever database For example, after sifting through a few pages of irrelevant results (missing\nthe gold document), MemGPT will pause the pagination and ask the user to help narrow the query -\n10Preprint\n51722\u202623b89 Your task is to provide the value for the following key: 94071\u2026\ufb00740.Showing 1 of 1 results (page 1/1):\u201cKey-value pair: key = 94071\u2026ff740, value = 88b32\u2026b3349\u201dsearch_archival_storage('94071\u2026ff740')The value of the provided key \"94071\u2026\ufb00740\" is \"88b32\u2026b3349\".I will now verify if this value is also a key in the archival memory.ArchivalStorage\ud83e\uddd1 \ud83d\udd0e\ud83e\udd16\ud83d\udce3\ud83e\udd16\ud83d\udcad\ud83e\udd16search_archival_storage('88bb32\u2026b3349')ArchivalStorage\ud83d\udd0e\ud83e\udd16This value of \u201c51722\u202623b89\u201d doesn\u2019t appear as a key.So, it is the \ufb01nal value in the nested sequence.\ud83d\udcad\ud83e\udd16\u2026\nFigure 8: Illustration of the nested key-value task In the example shown, MemGPT generates\nrepeatedly queries archival memory to search for the latest key Once archival memory reveals that\nthe current key\u2019s value is not also a key, MemGPT returns a message to the user with the final value in our evaluation, these questions are counted as failed answers, since there is no human-in-the-loop\nto answer MemGPT There is also a tradeoff in retrieved document capacity created by MemGPT more complex oper-\nation: assuming MemGPT has the same token budget as a fixed-context baseline (using the same\nLLM), a non-trivial portion of MemGPT\u2019s token budget will be consumed by system intstructions\nrequired for MemGPT\u2019s OS components (e.g function call schemas for memory management),\nmeaning that the total number of documents that can be held in-context at any given time is lower\nfor MemGPT than the baselines This tradeoff is observed in Figure 7: MemGPT has a lower av-\nerage accuracy than GPT-4 (though higher than GPT-3.5), but can trivially scale to larger numbers\nof documents To evaluate the fixed-context baselines against MemGPT past their default context\nlengths, we truncate the document segments returned by the retriever to fix the same number of\ndocuments into the available context As expected, document truncation reduces accuracy as doc-\numents shrink as the chance of the relevant snippet (in the gold document) being omitted grows We anticipate that MemGPT performance on document QA can be further improved with additional\ntask instructions that reduce the chance of MemGPT returning control to the user (e.g pausing to\nask questions) and increase the chance of MemGPT reading all documents ranked by the retriever 3.2.2 N ESTED KEY -VALUE RETRIEVAL (KV)\nWe introduce a new task based on the synthetic Key-Value retrieval proposed in prior work (Liu\net al., 2023a) The goal of this task is to demonstrate how MemGPT can collate information from\nmultiple data sources In the original KV task, the authors generated a synthetic dataset of key-value\npairs, where each key and value is a 128-bit UUID (universally unique identifier) The agent is then\ngiven a key, and asked to return the associated value for the key We create a version of the KV\ntask, nested KV retrieval , where values themselves may be keys, thus requiring the agent to perform\na multi-hop lookup In our setup, we fix the total number of UUIDs pairs to 140, corresponding to\nroughly 8k tokens (the context length of our GPT-4 baseline) We vary the total number of nesting\nlevels from 0 (the initial key-value pair\u2019s value is not a key) to 4 (ie 4 total KV lookups are required\nto find the final value), and sample 30 different ordering configurations including both the initial key\nposition and nesting key positions While GPT-3.5 and GPT-4 have good performance on the original KV tasks, both struggle in the\nnested KV task GPT-3.5 is unable to complete the nested variant of the task and has an immediate\n11Preprint\ndropoff in performance, hitting 0 percent accuracy at 1 nesting level (we observe that its primary\nfailure mode is to simply returns the original value) GPT-4 is better than GPT-3.5, but also suffers\nfrom a similar dropoff, and hits 0 percent accuracy by 4 nesting levels In GPT-4\u2019s case, we observe\nthat it often fails to recurse beyond a particular nesting level at simply returns the nested value at a\nprevious nesting level MemGPT on the other hand is unaffected with the number of nesting levels\nand is able to perform the nested lookup by accessing the key-value pairs stored in main memory\nrepeatedly via function queries", "summary": "Iteration 5 Revised Summary:\nThe retriever performance directly impacts the accuracy of GPT-3.5 and GPT-4. Accuracy improves with more documents in the context window. Despite sub-optimal retriever performance, MemGPT can find the desired document by making enough retriever calls. In the nested key-value task, MemGPT searches the archival memory for the latest key and returns the final value when the current key's value is not also a key. MemGPT has lower average accuracy than GPT-4 but can handle larger numbers of documents. Document truncation reduces accuracy, but additional task instructions can enhance MemGPT's performance. GPT-3.5 and GPT-4 struggle with nested KV retrieval, while MemGPT excels by accessing key-value pairs stored in main memory. The system uses ArchivalStorage for storing and retrieving documents. Retrieved documents, additional documents, and irrelevant results are part of the document retrieval process. The query is used to search for specific information within the documents. Nested sequences refer to a hierarchical structure within the data. Human-in-the-loop involves human intervention or feedback in the system. Baselines are reference points used for comparison. Document truncation involves cutting off or shortening a document. Document QA refers to the process of answering questions based on the content of a document. Control is the ability to manipulate or direct the system's behavior. Multi-hop lookup is the process of traversing multiple levels of information to find the desired result. A synthetic dataset is an artificially generated dataset used for training or evaluation. UUID is an abbreviation for a universally unique identifier. An agent is an entity that performs actions or tasks. Nesting levels refer to the depth or hierarchy of nested structures. Ordering configurations refer to different ways of arranging or organizing information. Original KV tasks are the initial key-value tasks without any modifications. There is a dropoff in performance when certain conditions are met. Nesting key positions indicate the location or placement of nested keys. Function queries are used to retrieve specific information or perform operations. Retriever performance directly affects the fixed-context baseline results. GPT-3.5 and GPT-4 have relatively low accuracy when few documents are retrieved. Accuracy improves when additional documents are included in the context window. MemGPT is not limited by sub-optimal retriever performance. MemGPT generates queries to search for the latest key and returns the final value. There is a tradeoff in the capacity for retrieved documents due to MemGPT's complex operation. MemGPT has lower average accuracy than GPT-4 but can handle larger numbers of documents. Document truncation reduces accuracy as relevant information may be omitted. MemGPT's performance on document QA can be enhanced with additional task instructions. The nested key-value retrieval task requires multi-hop lookup. GPT-3.5 and GPT-4 struggle with the nested KV task, but MemGPT is unaffected by nesting levels. MemGPT can perform nested lookup by repeatedly accessing key-value pairs stored in main memory using function queries. Liu et al. is a reference to a specific author or research paper. Retriever performance is crucial for overall accuracy improvement. Embedding-based ranking is a method of ordering or prioritizing information based on embeddings. Gold document refers to a document that contains the correct or desired information. Pagination involves dividing content into separate pages or sections. Token budget refers to the limit on the number of tokens that can be used. System instructions provide guidance or directives to the system. Memory management involves handling and organizing information stored in memory. Relevant snippets are specific sections or excerpts of a document that contain pertinent information. Task instructions provide guidance or instructions for performing a specific task. Multi-hop lookup involves traversing multiple levels of information to find the desired result. Synthetic datasets are artificially generated datasets used for training or evaluation. Universally unique identifier (UUID) is a unique identifier used to distinguish entities or objects. Nesting levels refer to the", "clean_entities": ["GPT-3.5", "GPT-4", "MemGPT", "ArchivalStorage", "retriever performance", "fixed-context baseline results", "accuracy", "retrieved documents", "additional documents", "context window", "sub-optimal retriever performance", "embedding-based ranking", "gold document", "retriever calls", "pagination", "irrelevant results", "query", "key-value pair", "key", "value", "archival memory", "nested sequence", "evaluation", "human-in-the-loop", "token budget", "system instructions", "memory management", "baselines", "average accuracy", "document truncation", "relevant snippet", "document QA", "task instructions", "control", "multi-hop lookup", "synthetic dataset", "key-value pairs", "UUID", "agent", "nesting levels", "ordering configurations", "original KV tasks", "dropoff in performance", "nesting key positions", "main memory", "function queries", "retriever performance translates directly to the fixed-context baseline results", "GPT-3.5 and GPT-4's accuracy is relatively low with few retrieved documents", "accuracy improves as additional documents are added to the context window", "MemGPT is not limited by sub-optimal retriever performance", "MemGPT will often stop paging through retriever results before exhausting the retriever database", "value of the provided key \"94071\u2026ff740\" is \"88b32\u2026b3349\"", "MemGPT generates queries to search for the latest key", "MemGPT returns a message to the user with the final value", "tradeoff in retrieved document capacity created by MemGPT's more complex operation", "MemGPT has a lower average accuracy than GPT-4 but can scale to larger numbers of documents", "document truncation reduces accuracy as the chance of the relevant snippet being omitted grows", "MemGPT performance on document QA can be further improved with additional task instructions", "nested key-value retrieval task requires multi-hop lookup", "GPT-3.5 and GPT-4 struggle in the nested KV task", "MemGPT is unaffected by the number of nesting levels", "MemGPT can perform nested lookup by accessing key-value pairs stored in main memory repeatedly via function queries", "Liu et al.", "Retriever performance", "Accuracy improvement", "Embedding-based ranking", "Gold document", "Pagination", "Token budget", "System instructions", "Memory management", "Document truncation", "Relevant snippet", "Document QA", "Task instructions", "Multi-hop lookup", "Synthetic dataset", "Universally unique identifier (UUID)", "Nesting levels", "Ordering configurations", "Main memory", "Function queries"], "dirty_entities": ["Entities:", "", "Keywords:", "", "Key Phrases:", "", "References:", "2023a", "", "Abstract Concepts:"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "Retriever performance and its impact on GPT-3.5 and GPT-4", "justification": "The summary highlights the importance of retriever performance in determining the accuracy of GPT-3.5 and GPT-4."}, {"topic": "MemGPT's ability to find desired documents despite sub-optimal retriever performance", "justification": "The summary mentions that MemGPT can still find the desired document by making enough retriever calls, even if the retriever performance is not optimal."}, {"topic": "MemGPT's performance in the nested key-value task", "justification": "The summary discusses how MemGPT excels in the nested key-value task by accessing key-value pairs stored in main memory."}, {"topic": "ArchivalStorage for storing and retrieving documents", "justification": "The summary mentions the use of ArchivalStorage as a system for storing and retrieving documents."}, {"topic": "Document retrieval process and the role of the query", "justification": "The summary explains the process of document retrieval and how the query is used to search for specific information within the documents."}, {"topic": "Document truncation and its impact on accuracy", "justification": "The summary states that document truncation reduces accuracy as relevant information may be omitted."}, {"topic": "MemGPT's performance enhancement with additional task instructions", "justification": "The summary mentions that MemGPT's performance on document QA can be enhanced with additional task instructions."}, {"topic": "GPT-3.5 and GPT-4's struggle with nested KV retrieval", "justification": "The summary highlights that GPT-3.5 and GPT-4 struggle with the nested key-value retrieval task."}, {"topic": "MemGPT's ability to handle larger numbers of documents", "justification": "The summary states that MemGPT has lower average accuracy than GPT-4 but can handle larger numbers of documents."}, {"topic": "Tradeoff in capacity for retrieved documents in MemGPT's complex operation", "justification": "The summary mentions that there is a tradeoff in the capacity for retrieved documents due to MemGPT's complex operation."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does the retriever performance impact the accuracy of GPT-3.5 and GPT-4?"}, {"question_type": "Analytical Question", "question": "What are the advantages and disadvantages of MemGPT's ability to handle larger numbers of documents compared to GPT-4?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a scenario where the retriever performance is perfect. How would this impact the overall accuracy of GPT-3.5 and GPT-4?"}, {"question_type": "Contextual/Relational Question", "question": "How does MemGPT's performance in the nested key-value retrieval task compare to that of GPT-3.5 and GPT-4?"}, {"question_type": "User-Interactive Question", "question": "As a user, how would you prioritize retriever performance and document truncation in order to optimize accuracy in the document retrieval process?"}], "knowledge_triplets": [{"subject": "retriever performance", "relationship": "translates directly to", "target": "fixed-context baseline results"}, {"subject": "accuracy", "relationship": "improves as", "target": "additional documents are added to the context window"}, {"subject": "MemGPT", "relationship": "is not limited by", "target": "sub-optimal retriever performance"}, {"subject": "MemGPT", "relationship": "will often stop", "target": "paging through retriever results before exhausting the retriever database"}, {"subject": "value of the provided key \"94071\u2026ff740\"", "relationship": "is", "target": "\"88b32\u2026b3349\""}, {"subject": "MemGPT generates", "relationship": "queries", "target": "to search for the latest key"}, {"subject": "MemGPT", "relationship": "returns", "target": "a message to the user with the final value"}, {"subject": "MemGPT's more complex operation", "relationship": "creates", "target": "tradeoff in retrieved document capacity"}, {"subject": "MemGPT has", "relationship": "a lower average accuracy than GPT-4 but can", "target": "scale to larger numbers of documents"}, {"subject": "document truncation", "relationship": "reduces accuracy as", "target": "the chance of the relevant snippet being omitted grows"}, {"subject": "nested key-value retrieval task", "relationship": "requires", "target": "multi-hop lookup"}, {"subject": "GPT-3.5 and GPT-4", "relationship": "struggle in", "target": "the nested KV task"}, {"subject": "MemGPT", "relationship": "is unaffected by", "target": "the number of nesting levels"}, {"subject": "MemGPT", "relationship": "can perform", "target": "nested lookup by accessing key-value pairs stored in main memory repeatedly via function queries"}, {"subject": "retriever performance", "relationship": "translates directly to", "target": "GPT-3.5 and GPT-4's accuracy"}, {"subject": "retriever performance", "relationship": "translates directly to", "target": "fixed-context baseline results"}, {"subject": "accuracy", "relationship": "improves as", "target": "additional documents are added to the context window"}, {"subject": "MemGPT", "relationship": "is not limited by", "target": "sub-optimal retriever performance"}, {"subject": "MemGPT", "relationship": "will often stop", "target": "paging through retriever results before exhausting the retriever database"}, {"subject": "value of the provided key \"94071\u2026ff740\"", "relationship": "is", "target": "\"88b32\u2026b3349\""}, {"subject": "MemGPT generates", "relationship": "queries", "target": "to search for the latest key"}, {"subject": "MemGPT", "relationship": "returns", "target": "a message to the user with the final value"}, {"subject": "MemGPT's more complex operation", "relationship": "creates", "target": "tradeoff in retrieved document capacity"}, {"subject": "MemGPT has", "relationship": "a lower average accuracy than GPT-4 but can", "target": "scale to larger numbers of documents"}, {"subject": "document truncation", "relationship": "reduces accuracy as", "target": "the chance of the relevant snippet being omitted grows"}, {"subject": "nested key-value retrieval task", "relationship": "requires", "target": "multi-hop lookup"}, {"subject": "GPT-3.5 and GPT-4", "relationship": "struggle in", "target": "the nested KV task"}, {"subject": "MemGPT", "relationship": "is unaffected by", "target": "the number of nesting levels"}, {"subject": "MemGPT", "relationship": "can perform", "target": "nested lookup by accessing key-value pairs stored in main memory repeatedly via function queries"}], "timestamp": "2024-01-14T17:33:28.891571"}, {"file_id": "2310.08560", "article": "Chunk # 8.\nMemGPT performance on the nested KV task demonstrates its\nability to combine multiple queries to perform multi-hop lookups 4 R ELATED WORK\nRecent works have looked at improving context length that can be processed in each LLM invoca-\ntion, improving search and retrieval for retrieval-augmented generation (RAG), and using language\nmodels to power interactive agents 4.1 L ONG -CONTEXT LLM S\nThe management of long contexts in LLMs is crucial for coherent and engaging dialogues for con-\nversational agents, and for corroborating and stitching together facts from diverse sources for LLMs\nused in question answering (QA) One approach to tackle the limitations of fixed-length context,\nis through recursive summarization (Wu et al., 2021a) In recursive summarization, the LLM often\ngenerates concise representations over a sliding window to fit them within the specified token length This summarization process is inherently lossy and can lead to the unintentional loss of relevant de-\ntails or subtle nuances Given the limitations of context length on many LLM-based applications,\nthere has been growing interest in improving the ability of LLMs to attend to longer sequences such\nas Press et al (2021); Guo et al (2021); Dong et al (2023); Beltagy et al (2020) MemGPT exploits\nand benefits from improvements to context length as it can store more information in MemGPT\u2019s\nmain memory (as an analogy, as GPU cache\u2019s get bigger, the processor can now compute through\nquicker as it would benefit from high cache hits) 4.2 S EARCH AND RETRIEVAL\nSearch and retrieval mechanisms especially for the retrieval-augmented generation (RAG) paradigm,\nhave been incorporated into conversational agents for tasks ranging from document question answer-\ning, customer support, to more general chatbots for entertainment These mechanisms often utilize\nexternal databases or internal conversation logs to provide contextually relevant responses Lin\net al (2023) for example, demonstrate how to train the retriever and LLM during instruction-tuning\nto improve the document recall Other works have looked at optimizing the retriever or the LLM in-\ndependently Ram et al (2023); Borgeaud et al (2022); Karpukhin et al (2020); Lewis et al (2020);\nGuu et al (2020) Trivedi et al (2022) interleave retrieval with Chain-of-Thoughts reasoning to\nimprove multi-step question answering In this work, we are agnostic for the retriever mechanism\nused; various retrieval mechanisms can be easily swapped or even combined as part of disk memory\nin MemGPT 4.3 LLM S AS AGENTS\nRecent work has explored augmenting LLMs with additional capabilities to act as agents in inter-\nactive environments Park et al (2023) propose adding memory to LLMs and using the LLM as\na planner, and observe emergent social behaviors in a multi-agent sandbox environment (inspired\nbyThe Sims video game) where agents can perform basic activities such as doing chores/hobbies,\ngoing to work, and conversing with other agents Nakano et al (2021) train models to search the\nweb before answering questions, and use similar pagination concepts to MemGPT to control the un-\nderlying context size in their web-browsing environment Yao et al (2022) showed that interleaving\nchain-of-thought reasoning (Wei et al., 2022) can further improve the planning ability of interactive\nLLM-based agents; similarly in MemGPT, LLM is able to \u2018plan out loud\u2019 when executing functions\n(see Figure 5 and 8 for examples) Liu et al (2023b) introduced a suite of LLM-as-an-agent bench-\nmarks to evaluate LLMs in interactive environments, including video games, thinking puzzles, and\n12Preprint\nweb shopping In contrast, our work focuses on tackling the problem of tackling the problem of\nequipping agents with long-term memory of user inputs 5 C ONCLUDING REMARKS AND FUTURE DIRECTIONS\nIn this paper, we introduced MemGPT, a novel LLM system inspired by operating systems to man-\nage the limited context windows of large language models By designing a memory hierarchy and\ncontrol flow analogous to traditional OSes, MemGPT provides the illusion of larger context re-\nsources for LLMs This OS-inspired approach was evaluated in two domains where existing LLM\nperformance is constrained by finite context lengths: document analysis and conversational agents For document analysis, MemGPT could process lengthy texts well beyond the context limits of\ncurrent LLMs by effectively paging relevant context in and out of memory For conversational\nagents, MemGPT enabled maintaining long-term memory, consistency, and evolvability over ex-\ntended dialogues Overall, MemGPT demonstrates that operating system techniques like hierarchi-\ncal memory management and interrupts can unlock the potential of LLMs even when constrained by\nfixed context lengths This work opens numerous avenues for future exploration, including apply-\ning MemGPT to other domains with massive or unbounded contexts, integrating different memory\ntier technologies like databases or caches, and further improving control flow and memory manage-\nment policies By bridging concepts from OS architecture into AI systems, MemGPT represents a\npromising new direction for maximizing the capabilities of LLMs within their fundamental limits", "summary": "MemGPT is a novel Large Language Model (LLM) that addresses the limitations of context length by implementing a memory hierarchy inspired by operating systems. It enables LLMs to process lengthy texts beyond the context limits and maintain long-term memory in conversational agents. By leveraging hierarchical memory management and interrupts, MemGPT unlocks the potential of LLMs within their constraints. This approach opens up opportunities for applying MemGPT to domains with massive or unbounded contexts, integrating different memory technologies, and improving control flow and memory management policies.", "clean_entities": [], "dirty_entities": ["Entities: MemGPT", "LLM", "RAG", "GPU", "Press", "Guo", "Dong", "Beltagy", "Lin", "Ram", "Borgeaud", "Karpukhin", "Lewis", "Guu", "Trivedi", "Park", "Nakano", "Yao", "Wei", "Liu", "", "Keywords: nested KV task", "multi-hop lookups", "long-context LLMs", "recursive summarization", "context length", "search and retrieval", "conversation logs", "document recall", "Chain-of-Thoughts reasoning", "multi-step question answering", "agents", "planner", "emergent social behaviors", "web browsing", "planning ability", "benchmarks", "document analysis", "memory hierarchy", "control flow", "operating systems", "finite context lengths", "memory management", "interrupts", "massive contexts", "unbounded contexts", "memory tier technologies", "databases", "caches", "memory management policies", "AI systems", "", "Phrases: MemGPT performance", "combine multiple queries", "multi-hop lookups", "long-context LLMs", "recursive summarization", "fixed-length context", "context length", "document question answering", "customer support", "chatbots", "retrieval mechanisms", "conversation logs", "document recall", "Chain-of-Thoughts reasoning", "multi-step question answering", "agents in interactive environments", "memory to LLMs", "emergent social behaviors", "web browsing", "planning ability", "LLM-as-an-agent benchmarks", "interactive environments", "long-term memory", "user inputs", "OS-inspired approach", "document analysis", "conversational agents", "memory management", "operating system techniques", "fixed context lengths", "hierarchical memory management", "memory tier technologies", "control flow", "memory management policies", "OS architecture", "AI systems", "", "References: Wu et al. (2021a)", "Press et al. (2021)", "Guo et al. (2021)", "Dong et al. (2023)", "Beltagy et al. (2020)", "Lin et al. (2023)", "Ram et al. (2023)", "Borgeaud et al. (2022)", "Karpukhin et al. (2020)", "Lewis et al. (2020)", "Guu et al. (2020)", "Trivedi et al. (2022)", "Park et al. (2023)", "Nakano et al. (2021)", "Yao et al. (2022)", "Wei et al. (2022)", "Liu et al. (2023b)"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "MemGPT", "justification": "MemGPT is the central subject of the summary, described as a novel Large Language Model that addresses the limitations of context length."}, {"topic": "Large Language Model (LLM)", "justification": "LLMs are mentioned as the category to which MemGPT belongs, and the summary highlights how MemGPT improves upon the limitations of LLMs."}, {"topic": "Memory Hierarchy", "justification": "The summary mentions that MemGPT implements a memory hierarchy inspired by operating systems, which is a key aspect of its design."}, {"topic": "Context Length Limitations", "justification": "The summary emphasizes that MemGPT addresses the limitations of context length, which is a significant challenge in language models."}, {"topic": "Hierarchical Memory Management", "justification": "The summary mentions that MemGPT leverages hierarchical memory management, which is a crucial feature of its design."}, {"topic": "Long-term Memory in Conversational Agents", "justification": "The summary highlights that MemGPT enables LLMs to maintain long-term memory in conversational agents, which is an important application of the model."}, {"topic": "Integrating Different Memory Technologies", "justification": "The summary mentions that MemGPT opens up opportunities for integrating different memory technologies, which is a potential area of improvement and exploration."}, {"topic": "Control Flow and Memory Management Policies", "justification": "The summary states that MemGPT improves control flow and memory management policies, indicating its impact on the functioning of language models."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How does MemGPT address the limitations of context length in Large Language Models (LLMs)?"}, {"question_type": "Analytical Question", "question": "What are the key components of MemGPT's memory hierarchy inspired by operating systems?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a scenario where MemGPT is applied to a domain with massive contexts, such as analyzing a large dataset. How could MemGPT's memory management capabilities enhance the performance of the language model?"}, {"question_type": "Contextual/Relational Question", "question": "How does MemGPT's hierarchical memory management and interrupts contribute to maintaining long-term memory in conversational agents?"}, {"question_type": "User-Interactive Question", "question": "How do you think MemGPT's ability to process lengthy texts beyond context limits could impact the development of chatbots or virtual assistants?"}], "knowledge_triplets": [{"subject": "MemGPT", "relationship": "demonstrates", "target": "ability"}, {"subject": "works", "relationship": "looked at", "target": "improving"}, {"subject": "LLMs", "relationship": "crucial", "target": "coherent and engaging dialogues"}, {"subject": "approach", "relationship": "tackle", "target": "limitations"}, {"subject": "recursive summarization", "relationship": "often generates", "target": "representations"}, {"subject": "summarization process", "relationship": "lossy", "target": "unintentional loss"}, {"subject": "context length", "relationship": "interest in improving", "target": "ability"}, {"subject": "MemGPT", "relationship": "exploits", "target": "benefits"}, {"subject": "Search and retrieval mechanisms", "relationship": "incorporated", "target": "conversational agents"}, {"subject": "mechanisms", "relationship": "utilize", "target": "databases or internal conversation logs"}, {"subject": "Lin et al", "relationship": "demonstrate", "target": "train"}, {"subject": "works", "relationship": "looked at", "target": "optimizing"}, {"subject": "Trivedi et al", "relationship": "interleave", "target": "retrieval"}, {"subject": "retriever mechanism", "relationship": "used", "target": "easily swapped"}, {"subject": "work", "relationship": "explored", "target": "augmenting LLMs"}, {"subject": "Park et al", "relationship": "propose", "target": "adding memory"}, {"subject": "Nakano et al", "relationship": "train models", "target": "search"}, {"subject": "Yao et al", "relationship": "showed", "target": "interleaving chain-of-thought reasoning"}, {"subject": "Liu et al", "relationship": "introduced", "target": "suite"}, {"subject": "work", "relationship": "focuses on", "target": "equipping agents"}, {"subject": "paper", "relationship": "introduced", "target": "MemGPT"}, {"subject": "MemGPT", "relationship": "manages", "target": "limited context windows"}, {"subject": "MemGPT", "relationship": "provides", "target": "illusion"}, {"subject": "approach", "relationship": "evaluated", "target": "two domains"}, {"subject": "MemGPT", "relationship": "process", "target": "lengthy texts"}, {"subject": "MemGPT", "relationship": "enabled", "target": "maintaining"}, {"subject": "MemGPT", "relationship": "demonstrates", "target": "operating system techniques"}, {"subject": "work", "relationship": "opens", "target": "avenues"}, {"subject": "MemGPT", "relationship": "applying", "target": "other domains"}, {"subject": "MemGPT", "relationship": "integrating", "target": "memory tier technologies"}, {"subject": "MemGPT", "relationship": "improving", "target": "control flow"}, {"subject": "MemGPT", "relationship": "represents", "target": "promising new direction"}, {"subject": "MemGPT", "relationship": "combines", "target": "multiple queries"}, {"subject": "LLM", "relationship": "processes", "target": "context length"}, {"subject": "LLM", "relationship": "used in", "target": "question answering"}, {"subject": "Wu et al.", "relationship": "propose", "target": "recursive summarization"}, {"subject": "LLM", "relationship": "generates", "target": "concise representations"}, {"subject": "LLM", "relationship": "benefits from", "target": "improvements to context length"}, {"subject": "MemGPT", "relationship": "stores", "target": "more information"}, {"subject": "Press et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "Guo et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "Dong et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "Beltagy et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "RAG", "relationship": "incorporates", "target": "search and retrieval mechanisms"}, {"subject": "RAG", "relationship": "utilizes", "target": "external databases or internal conversation logs"}, {"subject": "Lin et al.", "relationship": "train", "target": "retriever and LLM during instruction-tuning"}, {"subject": "Ram et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Borgeaud et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Karpukhin et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Lewis et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Guu et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Trivedi et al.", "relationship": "interleave", "target": "retrieval with Chain-of-Thoughts reasoning"}, {"subject": "MemGPT", "relationship": "allows", "target": "various retrieval mechanisms"}, {"subject": "Park et al.", "relationship": "augment", "target": "LLMs with additional capabilities"}, {"subject": "LLM", "relationship": "acts as", "target": "agent in interactive environments"}, {"subject": "Nakano et al.", "relationship": "train", "target": "models to search the web"}, {"subject": "Yao et al.", "relationship": "improve", "target": "planning ability of interactive LLM-based agents"}, {"subject": "Wei et al.", "relationship": "improve", "target": "planning ability of interactive LLM-based agents"}, {"subject": "Liu et al.", "relationship": "introduce", "target": "LLM-as-an-agent benchmarks"}, {"subject": "Liu et al.", "relationship": "evaluate", "target": "LLMs in interactive environments"}, {"subject": "MemGPT", "relationship": "enables", "target": "maintaining long-term memory"}, {"subject": "MemGPT", "relationship": "demonstrates", "target": "potential of LLMs"}, {"subject": "MemGPT", "relationship": "maximizes", "target": "capabilities of LLMs"}, {"subject": "MemGPT", "relationship": "applies", "target": "OS concepts to AI systems"}, {"subject": "MemGPT", "relationship": "represents", "target": "new direction for LLMs"}, {"subject": "MemGPT", "relationship": "opens", "target": "avenues for future exploration"}, {"subject": "MemGPT", "relationship": "combines", "target": "multiple queries"}, {"subject": "LLM", "relationship": "processes", "target": "context length"}, {"subject": "LLM", "relationship": "used in", "target": "question answering"}, {"subject": "Wu et al.", "relationship": "propose", "target": "recursive summarization"}, {"subject": "LLM", "relationship": "generates", "target": "concise representations"}, {"subject": "LLM", "relationship": "benefits from", "target": "improvements to context length"}, {"subject": "MemGPT", "relationship": "stores", "target": "more information"}, {"subject": "Press et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "Guo et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "Dong et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "Beltagy et al.", "relationship": "improve", "target": "ability of LLMs to attend to longer sequences"}, {"subject": "RAG", "relationship": "incorporates", "target": "search and retrieval mechanisms"}, {"subject": "RAG", "relationship": "utilizes", "target": "external databases or internal conversation logs"}, {"subject": "Lin et al.", "relationship": "train", "target": "retriever and LLM during instruction-tuning"}, {"subject": "Ram et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Borgeaud et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Karpukhin et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Lewis et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Guu et al.", "relationship": "optimize", "target": "retriever or LLM independently"}, {"subject": "Trivedi et al.", "relationship": "interleave", "target": "retrieval with Chain-of-Thoughts reasoning"}, {"subject": "MemGPT", "relationship": "allows", "target": "various retrieval mechanisms"}, {"subject": "Park et al.", "relationship": "augment", "target": "LLMs with additional capabilities"}, {"subject": "LLM", "relationship": "acts as", "target": "agent in interactive environments"}, {"subject": "Nakano et al.", "relationship": "train", "target": "models to search the web"}, {"subject": "Yao et al.", "relationship": "improve", "target": "planning ability of interactive LLM-based agents"}, {"subject": "Wei et al.", "relationship": "improve", "target": "planning ability of interactive LLM-based agents"}, {"subject": "Liu et al.", "relationship": "introduce", "target": "LLM-as-an-agent benchmarks"}, {"subject": "Liu et al.", "relationship": "evaluate", "target": "LLMs in interactive environments"}, {"subject": "MemGPT", "relationship": "enables", "target": "maintaining long-term memory"}, {"subject": "MemGPT", "relationship": "demonstrates", "target": "potential of LLMs"}, {"subject": "MemGPT", "relationship": "maximizes", "target": "capabilities of LLMs"}, {"subject": "MemGPT", "relationship": "applies", "target": "OS concepts to AI systems"}, {"subject": "MemGPT", "relationship": "represents", "target": "new direction for LLMs"}, {"subject": "MemGPT", "relationship": "opens", "target": "avenues for future exploration"}], "timestamp": "2024-01-14T17:34:13.586386"}, {"file_id": "2310.08560", "article": "Chunk # 9.\n5.1 L IMITATIONS\nOur reference implementation leverages OpenAI GPT-4 models that are fine-tuned specifically for\nfunction calling While the inner workings of OpenAI\u2019s models are proprietary and not publicly dis-\nclosed, OpenAI\u2019s API documentation states that when using function fine-tuned models, the function\nschema provided is converted into a system message that the model is trained to interpret through a\nfine-tuning process While GPT models that have been finetuned for function-calling still require a\nparser to verify outputs as valid function syntax, we observed that GPT-4 function fine-tuned models\nrarely made syntactic or semantic errors on the MemGPT function set, whereas GPT-3.5 finetuned\nmodels consistently generated incorrect function calls, or used attempted to use functions incor-\nrectly Similarly, we also found that the most popular the Llama 2 70B model variants (even those\nfine-tuned for function calling) would consistently generate incorrect function calls or even halluci-\nnate functions outside the providede schema At present reasonable performance is only achieved\nusing specialized GPT-4 models, however, we anticipate that future open-source models will even-\ntually improve to the point of enabling MemGPT-style operation, either through improvements in\nfine-tuning (e.g on larger function call datasets, or more specialized function call datasets), prompt\nengineering, or improved quality of base models Nonetheless, for the time being reliance on the\nperformance of proprietary closed-source models remains a significant limitation of this work REFERENCES\nIz Beltagy, Matthew E Peters, and Arman Cohan Longformer: The long-document transformer arXiv preprint arXiv:2004.05150 , 2020 Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Milli-\ncan, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al Improving language models by retrieving from trillions of tokens In International conference on\nmachine learning , pp 2206\u20132240 PMLR, 2022 Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al Language models are\nfew-shot learners Advances in neural information processing systems , 33:1877\u20131901, 2020 Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V Le, and Ruslan Salakhutdi-\nnov Transformer-xl: Attentive language models beyond a fixed-length context arXiv preprint\narXiv:1901.02860 , 2019 Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova Bert: Pre-training of deep\nbidirectional transformers for language understanding arXiv preprint arXiv:1810.04805 , 2018 13Preprint\nZican Dong, Tianyi Tang, Lunyi Li, and Wayne Xin Zhao A survey on long text modeling with\ntransformers arXiv preprint arXiv:2302.14502 , 2023 Mandy Guo, Joshua Ainslie, David Uthus, Santiago Ontanon, Jianmo Ni, Yun-Hsuan Sung, and\nYinfei Yang Longt5: Efficient text-to-text transformer for long sequences arXiv preprint\narXiv:2112.07916 , 2021 Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang Retrieval augmented\nlanguage model pre-training In International conference on machine learning , pp 3929\u20133938 PMLR, 2020 Gautier Izacard and Edouard Grave Leveraging passage retrieval with generative models for open\ndomain question answering arXiv preprint arXiv:2007.01282 , 2020 Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand\nJoulin, and Edouard Grave Unsupervised dense information retrieval with contrastive learning arXiv preprint arXiv:2112.09118 , 2021 Jeff Johnson, Matthijs Douze, and Herv \u00b4e J\u00b4egou Billion-scale similarity search with GPUs IEEE\nTransactions on Big Data , 7(3):535\u2013547, 2019 Vladimir Karpukhin, Barlas O \u02d8guz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi\nChen, and Wen-tau Yih Dense passage retrieval for open-domain question answering arXiv\npreprint arXiv:2004.04906 , 2020 Nikita Kitaev, \u0141ukasz Kaiser, and Anselm Levskaya Reformer: The efficient transformer arXiv\npreprint arXiv:2001.04451 , 2020 Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\nHeinrich K \u00a8uttler, Mike Lewis, Wen-tau Yih, Tim Rockt \u00a8aschel, et al Retrieval-augmented genera-\ntion for knowledge-intensive nlp tasks Advances in Neural Information Processing Systems , 33:\n9459\u20139474, 2020 Chin-Yew Lin Rouge: A package for automatic evaluation of summaries In Text summarization\nbranches out , pp 74\u201381, 2004 Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez,\nJacob Kahn, Gergely Szilvasy, Mike Lewis, Luke Zettlemoyer, and Scott Yih Ra-dit: Retrieval-\naugmented dual instruction tuning, 2023 Nelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and\nPercy Liang Lost in the middle: How language models use long contexts arXiv preprint\narXiv:2307.03172 , 2023a Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding,\nKaiwen Men, Kejuan Yang, et al AgentBench: Evaluating llms as agents arXiv preprint\narXiv:2308.03688 , 2023b Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher\nHesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al WebGPT: Browser-assisted\nquestion-answering with human feedback arXiv preprint arXiv:2112.09332 , 2021 Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al Training language models to follow\ninstructions with human feedback", "summary": "The limitations of our reference implementation using OpenAI GPT-4 models for function calling are due to the proprietary nature of the models and the need for a parser to verify outputs. GPT-4 models rarely make errors on the MemGPT function set, unlike GPT-3.5 models. Llama 2 70B model variants, even when fine-tuned for function calling, generate incorrect function calls or hallucinate functions outside the provided schema. While specialized GPT-4 models currently offer reasonable performance, future open-source models may improve through fine-tuning, prompt engineering, or better base models. However, reliance on proprietary closed-source models remains a significant limitation of this work.", "clean_entities": [], "dirty_entities": ["Entities: OpenAI GPT-4", "OpenAI GPT-3.5", "MemGPT", "Llama 2 70B", "Iz Beltagy", "Matthew E Peters", "Arman Cohan", "Sebastian Borgeaud", "Arthur Mensch", "Jordan Hoffmann", "Trevor Cai", "Eliza Rutherford", "Katie Milli-can", "George Bm Van Den Driessche", "Jean-Baptiste Lespiau", "Bogdan Damoc", "Aidan Clark", "Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V Le", "Ruslan Salakhutdi-nov", "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova", "Tom Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared D Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell", "Mandy Guo", "Joshua Ainslie", "David Uthus", "Santiago Ontanon", "Jianmo Ni", "Yun-Hsuan Sung", "Yinfei Yang", "Kelvin Guu", "Zora Tung", "Panupong Pasupat", "Gautier Izacard", "Edouard Grave", "Mathilde Caron", "Lucas Hosseini", "Sebastian Riedel", "Piotr Bojanowski", "Armand Joulin", "Jeff Johnson", "Matthijs Douze", "Herv \u00b4e J\u00b4egou", "Vladimir Karpukhin", "Barlas O \u02d8guz", "Sewon Min", "Patrick Lewis", "Ledell Wu", "Sergey Edunov", "Danqi Chen", "Wen-tau Yih", "Nikita Kitaev", "\u0141ukasz Kaiser", "Anselm Levskaya", "Ethan Perez", "Aleksandra Piktus", "Fabio Petroni", "Naman Goyal", "Heinrich K \u00a8uttler", "Mike Lewis", "Tim Rockt \u00a8aschel", "Chin-Yew Lin", "Xi Victoria Lin", "Xilun Chen", "Mingda Chen", "Weijia Shi", "Maria Lomeli", "Rich James", "Pedro Rodriguez", "Jacob Kahn", "Gergely Szilvasy", "Luke Zettlemoyer", "Scott Yih", "Nelson F Liu", "Kevin Lin", "John Hewitt", "Ashwin Paranjape", "Michele Bevilacqua", "Percy Liang", "Xiao Liu", "Hao Yu", "Hanchen Zhang", "Yifan Xu", "Xuanyu Lei", "Hanyu Lai", "Yu Gu", "Hangliang Ding", "Kaiwen Men", "Kejuan Yang", "Reiichiro Nakano", "Jacob Hilton", "Suchir Balaji", "Jeff Wu", "Long Ouyang", "Christina Kim", "Christopher Hesse", "Shantanu Jain", "Vineet Kosaraju", "William Saunders", "Diogo Almeida", "Carroll Wainwright", "Pamela Mishkin", "Chong Zhang", "Sandhini Agarwal", "Katarina Slama", "Alex Ray.", "", "Keywords: Limitations", "reference implementation", "OpenAI GPT-4", "OpenAI GPT-3.5", "fine-tuned models", "function calling", "function schema", "system message", "fine-tuning process", "syntactic errors", "semantic errors", "MemGPT function set", "function calls", "function call datasets", "prompt engineering", "base models", "specialized GPT-4 models", "Llama 2 70B model variants", "proprietary closed-source models", "performance", "open-source models.", "", "Phrases: OpenAI GPT-4 models", "fine-tuned specifically for function calling", "inner workings of OpenAI\u2019s models", "proprietary and not publicly disclosed", "OpenAI\u2019s API documentation", "function fine-tuned models", "fine-tuning process", "syntactic or semantic errors", "GPT-3.5 finetuned models", "incorrect function calls", "attempted to use functions incorrectly", "popular the Llama 2 70B model variants", "even those fine-tuned for function calling", "consistently generate incorrect function calls", "hallucinate functions outside the provided schema", "specialized GPT-4 models", "future open-source models", "improvements in fine-tuning", "larger function call datasets", "more specialized function call datasets", "prompt engineering", "improved quality of base models", "reasonable performance", "reliance on the performance of proprietary closed-source models", "significant limitation.", "", "References: Iz Beltagy", "Matthew E Peters", "Arman Cohan", "Sebastian Borgeaud", "Arthur Mensch", "Jordan Hoffmann", "Trevor Cai", "Eliza Rutherford", "Katie Milli-can", "George Bm Van Den Driessche", "Jean-Baptiste Lespiau", "Bogdan Damoc", "Aidan Clark", "Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V Le", "Ruslan Salakhutdi-nov", "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova", "Tom Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared D Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell", "Mandy Guo", "Joshua Ainslie", "David Uthus", "Santiago Ontanon", "Jianmo Ni", "Yun-Hsuan Sung", "Yinfei Yang", "Kelvin Guu", "Zora Tung", "Panupong Pasupat", "Gautier Izacard", "Edouard Grave", "Mathilde Caron", "Lucas Hosseini", "Sebastian Riedel", "Piotr Bojanowski", "Armand Joulin", "Jeff Johnson", "Matthijs Douze", "Herv \u00b4e J\u00b4egou", "Vladimir Karpukhin", "Barlas O \u02d8guz", "Sewon Min", "Patrick Lewis", "Ledell Wu", "Sergey Edunov", "Danqi Chen", "Wen-tau Yih", "Nikita Kitaev", "\u0141ukasz Kaiser", "Anselm Levskaya", "Ethan Perez", "Aleksandra Piktus", "Fabio Petroni", "Naman Goyal", "Heinrich K \u00a8uttler", "Mike Lewis", "Tim Rockt \u00a8aschel", "Chin-Yew Lin", "Xi Victoria Lin", "Xilun Chen", "Mingda Chen", "Weijia Shi", "Maria Lomeli", "Rich James", "Pedro Rodriguez", "Jacob Kahn", "Gergely Szilvasy", "Luke Zettlemoyer", "Scott Yih", "Nelson F Liu", "Kevin Lin", "John Hewitt", "Ashwin Paranjape", "Michele Bevilacqua", "Percy Liang", "Xiao Liu", "Hao Yu", "Hanchen Zhang", "Yifan Xu", "Xuanyu Lei", "Hanyu Lai", "Yu Gu", "Hangliang Ding", "Kaiwen Men", "Kejuan Yang", "Reiichiro Nakano", "Jacob Hilton", "Suchir Balaji", "Jeff Wu", "Long Ouyang", "Christina Kim", "Christopher Hesse", "Shantanu Jain", "Vineet Kosaraju", "William Saunders", "Diogo Almeida", "Carroll Wainwright", "Pamela Mishkin", "Chong Zhang", "Sandhini Agarwal", "Katarina Slama", "Alex Ray."], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "Limitations of reference implementation using OpenAI GPT-4 models for function calling", "justification": "The summary mentions the limitations of using OpenAI GPT-4 models for function calling, indicating a key topic of discussion."}, {"topic": "Proprietary nature of GPT-4 models and its impact on function calling", "justification": "The summary highlights the proprietary nature of GPT-4 models as a contributing factor to the limitations, warranting a separate topic."}, {"topic": "Need for a parser to verify outputs in the reference implementation", "justification": "The summary mentions the requirement of a parser to verify outputs, which is an important aspect to consider in the topic list."}, {"topic": "Comparison of error rates between GPT-4 and GPT-3.5 models on the MemGPT function set", "justification": "The summary discusses the difference in error rates between GPT-4 and GPT-3.5 models, indicating a topic related to model performance."}, {"topic": "Issues with Llama 2 70B model variants in generating incorrect function calls or hallucinating functions", "justification": "The summary highlights the problems with Llama 2 70B model variants in generating incorrect function calls or hallucinating functions, which is a distinct topic."}, {"topic": "Potential improvements through fine-tuning, prompt engineering, or better base models", "justification": "The summary mentions possible avenues for improvement, such as fine-tuning, prompt engineering, or better base models, which can be discussed as a separate topic."}, {"topic": "Significance of reliance on proprietary closed-source models as a limitation", "justification": "The summary emphasizes the reliance on proprietary closed-source models as a significant limitation, warranting a separate topic for discussion."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "What are the limitations of the reference implementation using OpenAI GPT-4 models for function calling?"}, {"question_type": "Analytical Question", "question": "How do the GPT-4 models differ from GPT-3.5 models in terms of making errors on the MemGPT function set?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a scenario where the Llama 2 70B model variants are fine-tuned for function calling. How might this impact the generation of function calls?"}, {"question_type": "Contextual/Relational Question", "question": "How does the reliance on proprietary closed-source models affect the overall limitations of the work on function calling?"}, {"question_type": "User-Interactive Question", "question": "As a developer, how might you address the limitations of the reference implementation using OpenAI GPT-4 models for function calling?"}], "knowledge_triplets": [{"subject": "OpenAI GPT-4", "relationship": "fine-tuned specifically for function calling", "target": "OpenAI GPT-3.5"}, {"subject": "OpenAI GPT-4", "relationship": "fine-tuned models", "target": "function calling"}, {"subject": "OpenAI GPT-4", "relationship": "fine-tuning process", "target": "function schema"}, {"subject": "OpenAI GPT-4", "relationship": "syntactic or semantic errors", "target": "GPT-3.5 finetuned models"}, {"subject": "GPT-4 function fine-tuned models", "relationship": "rarely made", "target": "syntactic or semantic errors"}, {"subject": "GPT-4 function fine-tuned models", "relationship": "MemGPT function set", "target": "incorrect function calls"}, {"subject": "Llama 2 70B model variants", "relationship": "even those fine-tuned for function calling", "target": "consistently generate incorrect function calls"}], "timestamp": "2024-01-14T17:35:06.523545"}, {"file_id": "2310.08560", "article": "Chunk # 10.\nAdvances in Neural Information Processing Systems , 35:\n27730\u201327744, 2022 Joon Sung Park, Joseph C O\u2019Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and\nMichael S Bernstein Generative agents: Interactive simulacra of human behavior arXiv preprint\narXiv:2304.03442 , 2023 David A Patterson, Garth Gibson, and Randy H Katz A case for redundant arrays of inexpensive\ndisks (raid) In Proceedings of the 1988 ACM SIGMOD international conference on Management\nof data , pp 109\u2013116, 1988 14Preprint\nOfir Press, Noah A Smith, and Mike Lewis Train short, test long: Attention with linear biases\nenables input length extrapolation arXiv preprint arXiv:2108.12409 , 2021 Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-\nBrown, and Yoav Shoham In-context retrieval-augmented language models arXiv preprint\narXiv:2302.00083 , 2023 Timo Schick, Jane Dwivedi-Yu, Roberto Dess `\u0131, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\nNicola Cancedda, and Thomas Scialom Toolformer: Language models can teach themselves to\nuse tools arXiv preprint arXiv:2302.04761 , 2023 SillyTavern Sillytavern docs: Character design, 2023 URL https://docs.sillytavern app/usage/core-concepts/characterdesign  Accessed: 10-11-2023 Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\nlay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al Llama 2: Open founda-\ntion and fine-tuned chat models arXiv preprint arXiv:2307.09288 , 2023 H Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal Interleaving re-\ntrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions ArXiv ,\nabs/2212.10509, 2022 URL https://api.semanticscholar.org/CorpusID:\n254877499  Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\u0141ukasz Kaiser, and Illia Polosukhin Attention is all you need Advances in neural informa-\ntion processing systems , 30, 2017 Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\nZhou, et al Chain-of-thought prompting elicits reasoning in large language models Advances in\nNeural Information Processing Systems , 35:24824\u201324837, 2022 Jeff Wu, Long Ouyang, Daniel M Ziegler, Nisan Stiennon, Ryan Lowe, Jan Leike, and Paul Chris-\ntiano Recursively summarizing books with human feedback arXiv preprint arXiv:2109.10862 ,\n2021a Jeff Wu, Long Ouyang, Daniel M Ziegler, Nisan Stiennon, Ryan Lowe, Jan Leike, and Paul Chris-\ntiano Recursively summarizing books with human feedback arXiv preprint arXiv:2109.10862 ,\n2021b Jing Xu, Arthur Szlam, and Jason Weston Beyond goldfish memory: Long-term open-domain\nconversation arXiv preprint arXiv:2107.07567 , 2021 Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao React: Synergizing reasoning and acting in language models arXiv preprint arXiv:2210.03629 ,\n2022 Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang,\nZi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al Judging llm-as-a-judge with mt-bench and\nchatbot arena arXiv preprint arXiv:2306.05685 , 2023 15", "summary": "Summary 7: Advances in Neural Information Processing Systems, 35:27730\u201327744, 2022, introduces generative agents, interactive simulacra of human behavior. Authored by Joon Sung Park, Joseph C O'Brien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein, the paper explores the capabilities of these agents and their potential applications. It was published as an arXiv preprint in 2023. The paper also discusses the importance of generative agents in character design and open-domain conversation. Additionally, it presents a case for redundant arrays of inexpensive disks (RAID) in storage technology. Other researchers, such as David A Patterson, Garth Gibson, Randy H Katz, Ofir Press, Noah A Smith, Mike Lewis, Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham, Timo Schick, Jane Dwivedi-Yu, Roberto Dess\u0131, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Niranjan Balasubramanian, Tushar Khot, Ashish Sabharwal, Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, and Denny Zhou have made significant contributions in this field, with their research on attention models, retrieval-augmented language models, tool learning, and reasoning in language models. SillyTavern is a platform that focuses on character design and provides documentation on the topic. Llama 2 is an open foundation for fine-tuned chat models. The concept of interleaving retrieval with chain-of-thought reasoning is explored for knowledge-intensive multi-step questions. Attention is emphasized as a crucial component in language models. Recursively summarizing books with human feedback is a method used to condense information. Long-term open-domain conversation is an area of interest. Reacting to prompts by combining reasoning and acting is studied in language models. Judging language models is done using mt-bench and chatbot arena.", "clean_entities": ["Advances in Neural Information Processing Systems", "Joon Sung Park", "Joseph C O'Brien", "Carrie J Cai", "Meredith Ringel Morris", "Percy Liang", "Michael S Bernstein", "David A Patterson", "Garth Gibson", "Randy H Katz", "Ofir Press", "Noah A Smith", "Mike Lewis", "Ori Ram", "Yoav Levine", "Itay Dalmedigos", "Dor Muhlgay", "Amnon Shashua", "Kevin Leyton-Brown", "Yoav Shoham", "Timo Schick", "Jane Dwivedi-Yu", "Roberto Dess\u0131", "Roberta Raileanu", "Maria Lomeli", "Luke Zettlemoyer", "Nicola Cancedda", "Thomas Scialom", "SillyTavern", "Hugo Touvron", "Louis Martin", "Kevin Stone", "Peter Albert", "Amjad Almahairi", "Yasmine Babaei", "Nikolay Bashlykov", "Soumya Batra", "Prajjwal Bhargava", "Shruti Bhosale", "Llama 2", "H Trivedi", "Niranjan Balasubramanian", "Tushar Khot", "Ashish Sabharwal", "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin", "Jason Wei", "Xuezhi Wang", "Dale Schuurmans", "Maarten Bosma", "Fei Xia", "Ed Chi", "Quoc V Le", "Denny Zhou", "Jeff Wu", "Long Ouyang", "Daniel M Ziegler", "Nisan Stiennon", "Ryan Lowe", "Jan Leike", "Paul Christiano", "Jing Xu", "Arthur Szlam", "Jason Weston", "Shunyu Yao", "Jeffrey Zhao", "Dian Yu", "Nan Du", "Izhak Shafran", "Karthik Narasimhan", "Yuan Cao", "Lianmin Zheng", "Wei-Lin Chiang", "Ying Sheng", "Siyuan Zhuang", "Zhanghao Wu", "Yonghao Zhuang", "Zi Lin", "Zhuohan Li", "Dacheng Li", "Eric Xing", "mt-bench", "chatbot arena", "Generative agents", "Interactive simulacra", "Redundant arrays of inexpensive disks (RAID)", "Attention with linear biases", "In-context retrieval-augmented language models", "Toolformer", "Character design", "Open foundation and fine-tuned chat models", "Interleaving retrieval with chain-of-thought reasoning", "Attention is all you need", "Chain-of-thought prompting", "Recursively summarizing books with human feedback", "Long-term open-domain conversation", "React: Synergizing reasoning and acting in language models", "Judging llm-as-a-judge with mt-bench and chatbot arena", "Advances in Neural Information Processing Systems", "Interactive simulacra of human behavior", "A case for redundant arrays of inexpensive disks (RAID)", "Train short", "In-context retrieval-augmented language models", "Toolformer: Language models can teach themselves to use tools", "SillyTavern docs: Character design", "Llama 2: Open foundation and fine-tuned chat models", "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions", "Attention is all you need", "Chain-of-thought prompting elicits reasoning in large language models", "Recursively summarizing books with human feedback", "Long-term open-domain conversation", "React: Synergizing reasoning and acting in language models", "Judging llm-as-a-judge with mt-bench and chatbot arena", "arXiv preprint arXiv:2304.03442", "Proceedings of the 1988 ACM SIGMOD international conference on Management of data", "arXiv preprint arXiv:2108.12409", "arXiv preprint arXiv:2302.00083", "arXiv preprint arXiv:2302.04761", "URL https://docs.sillytavern app/usage/core-concepts/characterdesign Accessed: 10-11-2023", "arXiv preprint arXiv:2307.09288", "ArXiv", "Advances in neural information processing systems", "Advances in Neural Information Processing Systems", "arXiv preprint arXiv:2109.10862", "arXiv preprint arXiv:2109.10862", "arXiv preprint arXiv:2107.07567", "arXiv preprint arXiv:2210.03629", "arXiv preprint arXiv:2306.05685", "Generative agents", "Simulacra of human behavior", "Redundant arrays of inexpensive disks", "Attention with linear biases", "In-context retrieval", "Tool learning", "Character design", "Fine-tuned chat models", "Chain-of-thought reasoning", "Language comprehension", "Recursively summarizing books", "Long-term conversation", "Reasoning and acting in language models", "Judging language models", "Knowledge-intensive multi-step questions"], "dirty_entities": ["Entities:", "", "Keywords:", "", "Key Phrases:", "35", "test long: Attention with linear biases enables input length extrapolation", "", "References:", "pp 109\u2013116", "1988", "abs/2212.10509", "30", "2017", "35:24824\u201324837", "2022", "2021a", "2021b", "", "Abstract Concepts:", "", "Output: Advances in Neural Information Processing Systems", "Joon Sung Park", "Joseph C O'Brien", "Carrie J Cai", "Meredith Ringel Morris", "Percy Liang", "Michael S Bernstein", "David A Patterson", "Garth Gibson", "Randy H Katz", "Ofir Press", "Noah A Smith", "Mike Lewis", "Ori Ram", "Yoav Levine", "Itay Dalmedigos", "Dor Muhlgay", "Amnon Shashua", "Kevin Leyton-Brown", "Yoav Shoham", "Timo Schick", "Jane Dwivedi-Yu", "Roberto Dess\u0131", "Roberta Raileanu", "Maria Lomeli", "Luke Zettlemoyer", "Nicola Cancedda", "Thomas Scialom", "SillyTavern", "Hugo Touvron", "Louis Martin", "Kevin Stone", "Peter Albert", "Amjad Almahairi", "Yasmine Babaei", "Nikolay Bashlykov", "Soumya Batra", "Prajjwal Bhargava", "Shruti Bhosale", "Llama 2", "H Trivedi", "Niranjan Balasubramanian", "Tushar Khot", "Ashish Sabharwal", "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "\u0141ukasz Kaiser", "Illia Polosukhin", "Jason Wei", "Xuezhi Wang", "Dale Schuurmans", "Maarten Bosma", "Fei Xia", "Ed Chi", "Quoc V Le", "Denny Zhou", "Jeff Wu", "Long Ouyang", "Daniel M Ziegler", "Nisan Stiennon", "Ryan Lowe", "Jan Leike", "Paul Christiano", "Jing Xu", "Arthur Szlam", "Jason Weston", "Shunyu Yao", "Jeffrey Zhao", "Dian Yu", "Nan Du", "Izhak Shafran", "Karthik Narasimhan", "Yuan Cao", "Lianmin Zheng", "Wei-Lin Chiang", "Ying Sheng", "Siyuan Zhuang", "Zhanghao Wu", "Yonghao Zhuang", "Zi Lin", "Zhuohan Li", "Dacheng Li", "Eric Xing", "mt-bench", "chatbot arena", "Generative agents", "Interactive simulacra", "Redundant arrays of inexpensive disks (RAID)", "Attention with linear biases", "In-context retrieval-augmented language models", "Toolformer", "Character design", "Open foundation and fine-tuned chat models", "Interleaving retrieval with chain-of-thought reasoning", "Attention is all you need", "Chain-of-thought prompting", "Recursively summarizing books with human feedback", "Long-term open-domain conversation", "React: Synergizing reasoning and acting in language models", "Judging llm-as-a-judge with mt-bench and chatbot arena", "arXiv preprint arXiv:2304.03442", "Proceedings of the 1988 ACM SIGMOD international conference on Management of data", "pp 109\u2013116", "1988", "arXiv preprint arXiv:2108.12409", "arXiv preprint arXiv:2302.00083", "arXiv preprint arXiv:2302.04761", "URL https://docs.sillytavern app/usage/core-concepts/characterdesign Accessed: 10-11-2023", "arXiv preprint arXiv:2307.09288", "ArXiv", "abs/2212.10509", "Advances in neural information processing systems", "30", "2017", "Advances in Neural Information Processing Systems", "35:24824\u201324837", "2022", "arXiv preprint arXiv:2109.10862", "2021a", "arXiv preprint arXiv:2109.10862", "2021b", "arXiv preprint arXiv:2107.07567", "arXiv preprint arXiv:2210.03629", "arXiv preprint arXiv:2306.05685", "Generative agents", "Simulacra of human behavior", "Redundant arrays of inexpensive disks", "Attention with linear biases", "In-context retrieval", "Tool learning", "Character design", "Fine-tuned chat models", "Chain-of-thought reasoning", "Language comprehension", "Recursively summarizing books", "Long-term conversation", "Reasoning and acting in language models", "Judging language models", "Knowledge-intensive multi-step questions"], "references": {"urls": ["https://api.semanticscholar.org/CorpusID", "https://docs.sillytavern.app/usage/core-concepts/characterdesign", "https://memgpt.ai", "https://api.semanticscholar.org/CorpusID:254877499", "https://docs.sillytavern"], "references": "Document infos:\n- CreationDate = D:20231013003536Z\n- Creator = LaTeX with hyperref\n- ModDate = D:20231013003536Z\n- PTEX.Fullbanner = This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n- Pages = 15\n- Producer = pdfTeX-1.40.25\n- Trapped = False\n\nReferences: 27\n- URL: 27\n\nURL References:\n- https://api.semanticscholar.org/CorpusID\n- 1901.02860\n- https://docs.sillytavern.app/usage/core-concepts/characterdesign\n- 2112.07916\n- 2307.09288\n- https://memgpt.ai\n- 2001.04451\n- 2304.03442\n- 2308.03688\n- 2302.04761\n- 2302.14502\n- https://api.semanticscholar.org/CorpusID:254877499\n- 2112.09118\n- 2007.01282\n- 2107.07567\n- 2004.04906\n- key.So\n- 2004.05150\n- 2108.12409\n- 2210.03629\n- 2306.05685\n- 2307.03172\n- 2109.10862\n- 2112.09332\n- 2302.00083\n- https://docs.sillytavern\n- 1810.04805"}, "topics": [{"topic": "Generative agents", "justification": "The paper introduces generative agents and explores their capabilities and potential applications."}, {"topic": "Character design", "justification": "The paper discusses the importance of generative agents in character design."}, {"topic": "Open-domain conversation", "justification": "The paper highlights the role of generative agents in open-domain conversation."}, {"topic": "Redundant arrays of inexpensive disks (RAID)", "justification": "The paper presents a case for RAID in storage technology."}, {"topic": "Attention models", "justification": "Other researchers have made significant contributions in this field, specifically in attention models."}, {"topic": "Retrieval-augmented language models", "justification": "Other researchers have made significant contributions in this field, specifically in retrieval-augmented language models."}, {"topic": "Tool learning", "justification": "Other researchers have made significant contributions in this field, specifically in tool learning."}, {"topic": "Reasoning in language models", "justification": "Other researchers have made significant contributions in this field, specifically in reasoning in language models."}, {"topic": "SillyTavern", "justification": "SillyTavern is mentioned as a platform that focuses on character design and provides documentation on the topic."}, {"topic": "Llama 2", "justification": "Llama 2 is mentioned as an open foundation for fine-tuned chat models."}, {"topic": "Interleaving retrieval with chain-of-thought reasoning", "justification": "The concept of interleaving retrieval with chain-of-thought reasoning is explored for knowledge-intensive multi-step questions."}, {"topic": "Attention as a crucial component in language models", "justification": "The paper emphasizes attention as a crucial component in language models."}, {"topic": "Recursively summarizing books with human feedback", "justification": "Recursively summarizing books with human feedback is mentioned as a method used to condense information."}, {"topic": "Long-term open-domain conversation", "justification": "Long-term open-domain conversation is mentioned as an area of interest."}, {"topic": "Reacting to prompts by combining reasoning and acting", "justification": "The paper discusses studying language models' ability to react to prompts by combining reasoning and acting."}, {"topic": "Judging language models using mt-bench and chatbot arena", "justification": "Judging language models using mt-bench and chatbot arena is mentioned as a method used in evaluating language models."}], "hypothetical_questions": [{"question_type": "Content-Based Question", "question": "How do generative agents, as discussed in the paper, contribute to character design and open-domain conversation?"}, {"question_type": "Analytical Question", "question": "What are the potential applications of generative agents, and how do they simulate human behavior?"}, {"question_type": "Creative/Scenario-Based Question", "question": "Imagine a world where generative agents have advanced to the point where they are indistinguishable from humans. How would this impact various industries, such as customer service or entertainment?"}, {"question_type": "Contextual/Relational Question", "question": "How does the concept of interleaving retrieval with chain-of-thought reasoning, as explored in the paper, enhance knowledge-intensive multi-step questions?"}, {"question_type": "User-Interactive Question", "question": "How would you judge the effectiveness of a language model that combines reasoning and acting in reacting to prompts? What criteria would you use to evaluate its performance?"}], "knowledge_triplets": [{"subject": "Advances in Neural Information Processing Systems", "relationship": "is published in", "target": "1988 ACM SIGMOD international conference on Management of data"}, {"subject": "Generative agents", "relationship": "are simulacra of", "target": "human behavior"}, {"subject": "Redundant arrays of inexpensive disks (RAID)", "relationship": "is a case for", "target": "Advances in Neural Information Processing Systems"}, {"subject": "Attention with linear biases", "relationship": "enables", "target": "input length extrapolation"}, {"subject": "In-context retrieval-augmented language models", "relationship": "are described in", "target": "Advances in Neural Information Processing Systems"}, {"subject": "Toolformer", "relationship": "is a language model that can", "target": "teach itself to use tools"}, {"subject": "Character design", "relationship": "is discussed in", "target": "SillyTavern docs"}, {"subject": "Attention is all you need", "relationship": "is a paper in", "target": "Advances in neural information processing systems"}, {"subject": "Chain-of-thought prompting", "relationship": "elicits reasoning in", "target": "large language models"}, {"subject": "Recursively summarizing books with human feedback", "relationship": "is a method described in", "target": "arXiv preprint arXiv:2109.10862"}, {"subject": "Long-term open-domain conversation", "relationship": "is explored in", "target": "arXiv preprint arXiv:2107.07567"}, {"subject": "React", "relationship": "synergizes reasoning and acting in", "target": "language models"}, {"subject": "Judging llm-as-a-judge with mt-bench and chatbot arena", "relationship": "is discussed in", "target": "arXiv preprint arXiv:2306.05685"}, {"subject": "Advances in Neural Information Processing Systems", "relationship": "Published in", "target": "35"}, {"subject": "Joon Sung Park", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Joseph C O'Brien", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Carrie J Cai", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Meredith Ringel Morris", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Percy Liang", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Michael S Bernstein", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "David A Patterson", "relationship": "Co-author of", "target": "A case for redundant arrays of inexpensive disks (RAID"}, {"subject": "Garth Gibson", "relationship": "Co-author of", "target": "A case for redundant arrays of inexpensive disks (RAID"}, {"subject": "Randy H Katz", "relationship": "Co-author of", "target": "A case for redundant arrays of inexpensive disks (RAID"}, {"subject": "Ofir Press", "relationship": "Co-author of", "target": "Train short, test long: Attention with linear biases enables input length extrapolation"}, {"subject": "Noah A Smith", "relationship": "Co-author of", "target": "Train short, test long: Attention with linear biases enables input length extrapolation"}, {"subject": "Mike Lewis", "relationship": "Co-author of", "target": "Train short, test long: Attention with linear biases enables input length extrapolation"}, {"subject": "Ori Ram", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Yoav Levine", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Itay Dalmedigos", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Dor Muhlgay", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Amnon Shashua", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Kevin Leyton-Brown", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Yoav Shoham", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Timo Schick", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Jane Dwivedi-Yu", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Roberto Dess\u0131", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Roberta Raileanu", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Maria Lomeli", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Luke Zettlemoyer", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Nicola Cancedda", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Thomas Scialom", "relationship": "Co-author of", "target": "Toolformer: Language models can teach themselves to use tools"}, {"subject": "Hugo Touvron", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Louis Martin", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Kevin Stone", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Peter Albert", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Amjad Almahairi", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Yasmine Babaei", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Nikolay Bashlykov", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Soumya Batra", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Prajjwal Bhargava", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "Shruti Bhosale", "relationship": "Co-author of", "target": "Llama 2: Open foundation and fine-tuned chat models"}, {"subject": "H Trivedi", "relationship": "Co-author of", "target": "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"}, {"subject": "Niranjan Balasubramanian", "relationship": "Co-author of", "target": "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"}, {"subject": "Tushar Khot", "relationship": "Co-author of", "target": "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"}, {"subject": "Ashish Sabharwal", "relationship": "Co-author of", "target": "Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions"}, {"subject": "Ashish Vaswani", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Noam Shazeer", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Niki Parmar", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Jakob Uszkoreit", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Llion Jones", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Aidan N Gomez", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "\u0141ukasz Kaiser", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Illia Polosukhin", "relationship": "Co-author of", "target": "Attention is all you need"}, {"subject": "Jason Wei", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Xuezhi Wang", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Dale Schuurmans", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Maarten Bosma", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Fei Xia", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Ed Chi", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Quoc V Le", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Denny Zhou", "relationship": "Co-author of", "target": "Chain-of-thought prompting elicits reasoning in large language models"}, {"subject": "Jeff Wu", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Long Ouyang", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Daniel M Ziegler", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Nisan Stiennon", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Ryan Lowe", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Jan Leike", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Paul Christiano", "relationship": "Co-author of", "target": "Recursively summarizing books with human feedback"}, {"subject": "Jing Xu", "relationship": "Co-author of", "target": "Beyond goldfish memory: Long-term open-domain conversation"}, {"subject": "Arthur Szlam", "relationship": "Co-author of", "target": "Beyond goldfish memory: Long-term open-domain conversation"}, {"subject": "Jason Weston", "relationship": "Co-author of", "target": "Beyond goldfish memory: Long-term open-domain conversation"}, {"subject": "Shunyu Yao", "relationship": "Co-author of", "target": "React: Synergizing reasoning and acting in language models"}, {"subject": "Advances in Neural Information Processing Systems", "relationship": "is published in", "target": "1988 ACM SIGMOD international conference on Management of data"}, {"subject": "Generative agents", "relationship": "are simulacra of", "target": "human behavior"}, {"subject": "Redundant arrays of inexpensive disks (RAID)", "relationship": "is a case for", "target": "Advances in Neural Information Processing Systems"}, {"subject": "Attention with linear biases", "relationship": "enables", "target": "input length extrapolation"}, {"subject": "In-context retrieval-augmented language models", "relationship": "are described in", "target": "Advances in Neural Information Processing Systems"}, {"subject": "Toolformer", "relationship": "is a language model that can", "target": "teach itself to use tools"}, {"subject": "Character design", "relationship": "is discussed in", "target": "SillyTavern docs"}, {"subject": "Attention is all you need", "relationship": "is a paper in", "target": "Advances in neural information processing systems"}, {"subject": "Chain-of-thought prompting", "relationship": "elicits reasoning in", "target": "large language models"}, {"subject": "Recursively summarizing books with human feedback", "relationship": "is a method described in", "target": "arXiv preprint arXiv:2109.10862"}, {"subject": "Long-term open-domain conversation", "relationship": "is explored in", "target": "arXiv preprint arXiv:2107.07567"}, {"subject": "React", "relationship": "synergizes reasoning and acting in", "target": "language models"}, {"subject": "Judging llm-as-a-judge with mt-bench and chatbot arena", "relationship": "is discussed in", "target": "arXiv preprint arXiv:2306.05685"}, {"subject": "Advances in Neural Information Processing Systems", "relationship": "Published in", "target": "35"}, {"subject": "Joon Sung Park", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Joseph C O'Brien", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Carrie J Cai", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Meredith Ringel Morris", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Percy Liang", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "Michael S Bernstein", "relationship": "Co-author of", "target": "Generative agents: Interactive simulacra of human behavior"}, {"subject": "David A Patterson", "relationship": "Co-author of", "target": "A case for redundant arrays of inexpensive disks (RAID"}, {"subject": "Garth Gibson", "relationship": "Co-author of", "target": "A case for redundant arrays of inexpensive disks (RAID"}, {"subject": "Randy H Katz", "relationship": "Co-author of", "target": "A case for redundant arrays of inexpensive disks (RAID"}, {"subject": "Ofir Press", "relationship": "Co-author of", "target": "Train short, test long: Attention with linear biases enables input length extrapolation"}, {"subject": "Noah A Smith", "relationship": "Co-author of", "target": "Train short, test long: Attention with linear biases enables input length extrapolation"}, {"subject": "Mike Lewis", "relationship": "Co-author of", "target": "Train short, test long: Attention with linear biases enables input length extrapolation"}, {"subject": "Ori Ram", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Yoav Levine", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Itay Dalmedigos", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Dor Muhlgay", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Amnon Shashua", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}, {"subject": "Kevin Leyton-Brown", "relationship": "Co-author of", "target": "In-context retrieval-augmented language models"}], "timestamp": "2024-01-14T17:37:35.951141"}]